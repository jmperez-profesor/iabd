---
title: Tasks NLP con los Transformers y pipelines de Hugging Face
description: Apuntes, prÃ¡cticas, ejercicio del curso de especializaciÃ³n en IA y Big Data. 
---

## Objetivos de la sesiÃ³n
- Comprender la arquitectura Transformer
- Aprender a usar la librerÃ­a Hugging Face Transformers
- Realizar tareas NLP con pipelines

# Â¿QuÃ© es un task?

Un "task" en Hugging Face describe el tipo de problema que un modelo puede resolver.
Permite buscar, probar y reutilizar modelos segÃºn la tarea (task) deseada.

![Tasks (tareas) en Hugging Face](./img/01hf-tasks.png)
*Tasks (tareas) en Hugging Face*

# Uso de Hugging Face para tareas de visiÃ³n por computadora

Hugging Face tambiÃ©n proporciona una amplia colecciÃ³n de modelos preentrenados para tareas de visiÃ³n artificial. Con todos estos modelos alojados previamente entrenados, podemos crear aplicaciones interesantes que detectan objetos en imÃ¡genes, la edad de una persona y mÃ¡s. En este tema, aprenderemos a realizar las primeras cuatro tareas utilizando modelos de Hugging Face. 

# ðŸ”¥ IntroducciÃ³n: El Poder de los Transformers

## ðŸŽ¬ Demo en Vivo: "5 LÃ­neas de CÃ³digo, Infinitas Posibilidades"

### Â¡Empezamos con magia! âœ¨

```python {hl_lines="1 2" linenums="1"} 
from transformers import pipeline

# Â¡Una lÃ­nea para crear un analizador de sentimientos!
classifier = pipeline("sentiment-analysis")
result = classifier("Â¡Este taller va a ser increÃ­ble!")
print(result)  # [{'label': 'POSITIVE', 'score': 0.9998}]
```

**Â¿QuÃ© acabamos de hacer?** En 3 lÃ­neas hemos creado un sistema de IA que entiende emociones humanas. Â¡Sin entrenar nada, sin configurar modelos complejos!

## ðŸ§  Conceptos Clave (Just-in-Time Learning)

### Â¿QuÃ© son los Pipelines de Hugging Face?

Los **pipelines** son como "herramientas mÃ¡gicas" que encapsulan modelos complejos en interfaces sÃºper simples:

```python
# Formato general
pipeline("tarea", model="modelo_especÃ­fico")
```

### ðŸŽ¯ Tareas NLP Principales

| Tarea | Pipeline | Ejemplo de Uso |
|-------|----------|----------------|
| **AnÃ¡lisis de Sentimientos** | `sentiment-analysis` | Redes sociales, reviews |
| **ClasificaciÃ³n de Texto** | `text-classification` | Categorizar noticias, emails |
| **GeneraciÃ³n de Texto** | `text-generation` | Chatbots, escritura creativa |
| **TraducciÃ³n** | `translation` | Apps multiidioma |
| **Resumen** | `summarization` | ResÃºmenes automÃ¡ticos |

### ðŸ—ï¸ Arquitectura Simplificada

```
Texto de Entrada â†’ TokenizaciÃ³n â†’ Modelo Transformer â†’ Post-procesado â†’ Resultado
```

## ðŸš€ Demo Interactiva: "Probemos Juntos"

### Experimento 1: Sentimientos Multiidioma
```python {linenums="1"} 
classifier = pipeline("sentiment-analysis")

textos = [
    "I love this workshop!",
    "Este taller es aburrido",
    "Je suis trÃ¨s content",
    "ðŸ˜ðŸŽ‰âœ¨"
]

for texto in textos:
    resultado = classifier(texto)
    print(f"{texto} â†’ {resultado[0]['label']} ({resultado[0]['score']:.2f})")
```

### Experimento 2: GeneraciÃ³n InstantÃ¡nea
```python {linenums="1"} 
generator = pipeline("text-generation", model="gpt2")
prompt = "En el futuro, la inteligencia artificial"
resultado = generator(prompt, max_length=50, num_return_sequences=2)

for i, texto in enumerate(resultado):
    print(f"VersiÃ³n {i+1}: {texto['generated_text']}")
```

## ðŸŽ¯ Â¿Por quÃ© funciona tan bien?

### El Secreto: Modelos Pre-entrenados
- **Millones de parÃ¡metros** entrenados en enormes datasets
- **Transfer Learning**: Conocimiento general aplicado a tareas especÃ­ficas
- **Fine-tuning**: AdaptaciÃ³n a dominios especÃ­ficos

### Ventajas de Hugging Face
- âœ… **Simplicidad**: Una lÃ­nea de cÃ³digo para tareas complejas
- âœ… **Variedad**: Miles de modelos disponibles
- âœ… **Comunidad**: Modelos compartidos y mejorados constantemente
- âœ… **Flexibilidad**: Desde uso bÃ¡sico hasta personalizaciÃ³n avanzada

## ðŸŽ® PreparaciÃ³n para los Retos

### InstalaciÃ³n RÃ¡pida
```bash
pip install transformers torch datasets evaluate
```

### Estructura mental para los retos
1. **Identifica el problema** â†’ Â¿QuÃ© tarea NLP necesito?
2. **Elige el pipeline** â†’ Â¿CuÃ¡l es el mÃ¡s adecuado?
3. **Experimenta** â†’ Prueba con diferentes textos
4. **Optimiza** â†’ Ajusta parÃ¡metros y modelos
5. **EvalÃºa** â†’ Â¿Funciona bien para mi caso de uso?

## ðŸ† Â¡Listos para el Primer Reto!

Ahora que hemos visto la magia en acciÃ³n, es hora de crear nuestro primer proyecto real: **un detector de emociones para redes sociales**.

**Â¿El objetivo?** Ayudar a una empresa a monitorizar la percepciÃ³n de su marca en Twitter.

---

## ðŸ“š Recursos Adicionales

- [DocumentaciÃ³n oficial de Transformers](https://huggingface.co/docs/transformers)
- [Hugging Face Model Hub](https://huggingface.co/models)
- [Curso completo de NLP](https://huggingface.co/learn/nlp-course)

# ðŸ† Reto 1: Detector de Emociones en Redes Sociales

**â±ï¸ Tiempo:** 30 minutos  
**ðŸŽ¯ Nivel:** Principiante  
**ðŸš€ Objetivo:** Crear un analizador de sentimientos para monitorizar la percepciÃ³n de marca en Twitter

## ðŸŽ¬ Contexto y MotivaciÃ³n (5 min)

### El Problema Real
Una startup de tecnologÃ­a quiere monitorizar quÃ© dice la gente sobre su nueva app en redes sociales. Necesitan:
- Detectar comentarios positivos y negativos automÃ¡ticamente
- Identificar crisis de reputaciÃ³n temprano
- Medir el impacto de sus campaÃ±as de marketing

### Â¿Por QuÃ© es Importante?
- **85% de las empresas** usan anÃ¡lisis de sentimientos para tomar decisiones
- **DetecciÃ³n temprana** de problemas puede ahorrar millones
- **AutomatizaciÃ³n** permite analizar miles de comentarios por minuto

## ðŸ§  TeorÃ­a Just-in-Time (10 min)

### Â¿QuÃ© es el AnÃ¡lisis de Sentimientos?

El anÃ¡lisis de sentimientos clasifica texto segÃºn la **emociÃ³n** o **actitud** que expresa:

```
"Â¡Me encanta esta app!" â†’ POSITIVO (0.95)
"Esta app es terrible" â†’ NEGATIVO (0.89)
"La app funciona bien" â†’ NEUTRAL (0.72)
```

### Modelos Disponibles en Hugging Face

| Modelo | Idioma | Especialidad | Uso Recomendado |
|--------|--------|--------------|-----------------|
| `cardiffnlp/twitter-roberta-base-sentiment-latest` | EN | Twitter | Redes sociales |
| `nlptown/bert-base-multilingual-uncased-sentiment` | Multi | General | Textos variados |
| `pysentimiento/robertuito-sentiment-analysis` | ES | EspaÃ±ol | Textos en espaÃ±ol |

### ParÃ¡metros Importantes

```python
classifier = pipeline(
    "sentiment-analysis",
    model="cardiffnlp/twitter-roberta-base-sentiment-latest",
    return_all_scores=True  # Ver todas las probabilidades
)
```

## ðŸ’» ImplementaciÃ³n Guiada (10 min)

### Paso 1: ConfiguraciÃ³n BÃ¡sica

```python
from transformers import pipeline
import pandas as pd

# Crear el clasificador
classifier = pipeline("sentiment-analysis")

# Datos de ejemplo (simula tweets reales)
tweets = [
    "Â¡Esta nueva app es increÃ­ble! ðŸš€",
    "La app se cuelga constantemente ðŸ˜¡",
    "Funciona bien, pero podrÃ­a mejorar",
    "Â¡Gracias por esta herramienta tan Ãºtil! â¤ï¸",
    "No entiendo cÃ³mo usarla, muy confusa",
    "Perfecta para lo que necesitaba ðŸ‘Œ"
]
```
### Paso 2: AnÃ¡lisis BÃ¡sico

```python
# Analizar cada tweet
resultados = []
for tweet in tweets:
    resultado = classifier(tweet)
    resultados.append({
        'tweet': tweet,
        'sentimiento': resultado[0]['label'],
        'confianza': resultado[0]['score']
    })

# Mostrar resultados
for r in resultados:
    print(f"Tweet: {r['tweet']}")
    print(f"Sentimiento: {r['sentimiento']} (Confianza: {r['confianza']:.2f})")
    print("-" * 50)
```

### Paso 3: AnÃ¡lisis Avanzado con MÃºltiples Modelos

```python
# Comparar diferentes modelos
modelos = [
    "cardiffnlp/twitter-roberta-base-sentiment-latest",
    "nlptown/bert-base-multilingual-uncased-sentiment"
]

def comparar_modelos(texto, modelos):
    resultados = {}
    for modelo in modelos:
        classifier = pipeline("sentiment-analysis", model=modelo)
        resultado = classifier(texto)
        resultados[modelo.split('/')[-1]] = {
            'label': resultado[0]['label'],
            'score': resultado[0]['score']
        }
    return resultados

# Probar con un tweet especÃ­fico
tweet_test = "Esta app es genial pero tiene algunos bugs"
comparacion = comparar_modelos(tweet_test, modelos)

print(f"Tweet: {tweet_test}")
for modelo, resultado in comparacion.items():
    print(f"{modelo}: {resultado['label']} ({resultado['score']:.2f})")
```

### Paso 4: Dashboard Simple

```python
import matplotlib.pyplot as plt

def crear_dashboard(resultados):
    # Contar sentimientos
    sentimientos = [r['sentimiento'] for r in resultados]
    conteo = pd.Series(sentimientos).value_counts()
    
    # Crear grÃ¡fico
    plt.figure(figsize=(10, 6))
    
    # GrÃ¡fico de barras
    plt.subplot(1, 2, 1)
    conteo.plot(kind='bar', color=['green', 'red', 'gray'])
    plt.title('DistribuciÃ³n de Sentimientos')
    plt.ylabel('NÃºmero de Tweets')
    
    # GrÃ¡fico de confianza
    plt.subplot(1, 2, 2)
    confianzas = [r['confianza'] for r in resultados]
    plt.hist(confianzas, bins=10, alpha=0.7, color='blue')
    plt.title('DistribuciÃ³n de Confianza')
    plt.xlabel('Nivel de Confianza')
    plt.ylabel('Frecuencia')
    
    plt.tight_layout()
    plt.show()

# Crear dashboard
crear_dashboard(resultados)
```

## ðŸŽ¯ ExperimentaciÃ³n Libre (5 min)

### DesafÃ­os para Explorar

1. **Prueba con Emojis:**
   ```python
   tweets_emojis = ["ðŸ˜", "ðŸ˜¡", "ðŸ¤”", "ðŸ‘", "ðŸ’”"]
   # Â¿CÃ³mo los interpreta el modelo?
   ```

2. **Textos Ambiguos:**
   ```python
   tweets_ambiguos = [
       "Esta app es... interesante",
       "Bueno, funciona",
       "No estÃ¡ mal, supongo"
   ]
   ```

3. **Diferentes Idiomas:**
   ```python
   tweets_multiidioma = [
       "I love this app!",
       "J'adore cette application!",
       "Â¡Me encanta esta aplicaciÃ³n!"
   ]
   ```

### Preguntas para Reflexionar
- Â¿QuÃ© modelo funciona mejor para tu caso de uso?
- Â¿CÃ³mo manejas la incertidumbre (scores bajos)?
- Â¿QuÃ© harÃ­as con sentimientos neutrales?

## ðŸ… Criterios de Ã‰xito

Al completar este reto, deberÃ­as poder:
- âœ… Implementar anÃ¡lisis de sentimientos bÃ¡sico
- âœ… Comparar diferentes modelos
- âœ… Interpretar scores de confianza
- âœ… Crear visualizaciones simples
- âœ… Identificar limitaciones del modelo

## ðŸš€ Extensiones Opcionales

### Para los MÃ¡s RÃ¡pidos:
1. **AnÃ¡lisis en Tiempo Real:** Conectar con la API de Twitter
2. **Alertas AutomÃ¡ticas:** Notificar cuando el sentimiento baja del 70%
3. **AnÃ¡lisis Temporal:** Seguir la evoluciÃ³n del sentimiento por horas/dÃ­as

### CÃ³digo de ExtensiÃ³n:
```python
def monitor_sentimiento(tweets, umbral=0.7):
    """Monitoriza sentimientos y genera alertas"""
    negativos = []
    for tweet in tweets:
        resultado = classifier(tweet)
        if resultado[0]['label'] == 'NEGATIVE' and resultado[0]['score'] > umbral:
            negativos.append({
                'tweet': tweet,
                'score': resultado[0]['score']
            })
    
    if negativos:
        print(f"ðŸš¨ ALERTA: {len(negativos)} tweets muy negativos detectados!")
        for neg in negativos:
            print(f"- {neg['tweet']} (Score: {neg['score']:.2f})")
```

## ðŸŽ¯ PrÃ³ximo Reto

Â¡Excelente trabajo! Has creado tu primer sistema de anÃ¡lisis de sentimientos. 

En el siguiente reto, subiremos el nivel: **clasificaremos noticias automÃ¡ticamente** para crear un sistema de organizaciÃ³n inteligente.

[ðŸ‘‰ Ir al Reto 2: Clasificador de Noticias](03_reto2_clasificacion.md)

---

## ðŸ“š Recursos del Reto

- [Modelos de Sentimientos en Hugging Face](https://huggingface.co/models?pipeline_tag=text-classification&sort=downloads)
- [DocumentaciÃ³n de Text Classification](https://huggingface.co/docs/transformers/tasks/sequence_classification)