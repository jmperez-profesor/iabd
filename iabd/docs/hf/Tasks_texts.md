---
title: Tasks NLP con los Transformers y pipelines de Hugging Face
description: Apuntes, prÃ¡cticas, ejercicio del curso de especializaciÃ³n en IA y Big Data. 
---

## Objetivos de la sesiÃ³n
- Comprender la arquitectura Transformer
- Aprender a usar la librerÃ­a Hugging Face Transformers
- Realizar tareas NLP con pipelines

# Â¿QuÃ© es un task?

Un "task" en Hugging Face describe el tipo de problema que un modelo puede resolver.
Permite buscar, probar y reutilizar modelos segÃºn la tarea (task) deseada.

![Tasks (tareas) en Hugging Face](./img/01hf-tasks.png)
*Tasks (tareas) en Hugging Face*

# Uso de Hugging Face para tareas de visiÃ³n por computadora

Hugging Face tambiÃ©n proporciona una amplia colecciÃ³n de modelos preentrenados para tareas de visiÃ³n artificial. Con todos estos modelos alojados previamente entrenados, podemos crear aplicaciones interesantes que detectan objetos en imÃ¡genes, la edad de una persona y mÃ¡s. En este tema, aprenderemos a realizar las primeras cuatro tareas utilizando modelos de Hugging Face. 

# ğŸ”¥ IntroducciÃ³n: El Poder de los Transformers

## ğŸ¬ Demo en Vivo: "5 LÃ­neas de CÃ³digo, Infinitas Posibilidades"

### Â¡Empezamos con magia! âœ¨

```python
from transformers import pipeline

# Â¡Una lÃ­nea para crear un analizador de sentimientos!
classifier = pipeline("sentiment-analysis")
result = classifier("Â¡Este taller va a ser increÃ­ble!")
print(result)  # [{'label': 'POSITIVE', 'score': 0.9998}]
```

**Â¿QuÃ© acabamos de hacer?** En 3 lÃ­neas hemos creado un sistema de IA que entiende emociones humanas. Â¡Sin entrenar nada, sin configurar modelos complejos!

## ğŸ§  Conceptos Clave (Just-in-Time Learning)

### Â¿QuÃ© son los Pipelines de Hugging Face?

Los **pipelines** son como "herramientas mÃ¡gicas" que encapsulan modelos complejos en interfaces sÃºper simples:

```python
# Formato general
pipeline("tarea", model="modelo_especÃ­fico")
```

### ğŸ¯ Tareas NLP Principales

| Tarea | Pipeline | Ejemplo de Uso |
|-------|----------|----------------|
| **AnÃ¡lisis de Sentimientos** | `sentiment-analysis` | Redes sociales, reviews |
| **ClasificaciÃ³n de Texto** | `text-classification` | Categorizar noticias, emails |
| **GeneraciÃ³n de Texto** | `text-generation` | Chatbots, escritura creativa |
| **TraducciÃ³n** | `translation` | Apps multiidioma |
| **Resumen** | `summarization` | ResÃºmenes automÃ¡ticos |

### ğŸ—ï¸ Arquitectura Simplificada

```
Texto de Entrada â†’ TokenizaciÃ³n â†’ Modelo Transformer â†’ Post-procesado â†’ Resultado
```

## ğŸš€ Demo Interactiva: "Probemos Juntos"

### Experimento 1: Sentimientos Multiidioma
```python
classifier = pipeline("sentiment-analysis")

textos = [
    "I love this workshop!",
    "Este taller es aburrido",
    "Je suis trÃ¨s content",
    "ğŸ˜ğŸ‰âœ¨"
]

for texto in textos:
    resultado = classifier(texto)
    print(f"{texto} â†’ {resultado[0]['label']} ({resultado[0]['score']:.2f})")
```

### Experimento 2: GeneraciÃ³n InstantÃ¡nea
```python
generator = pipeline("text-generation", model="gpt2")
prompt = "En el futuro, la inteligencia artificial"
resultado = generator(prompt, max_length=50, num_return_sequences=2)

for i, texto in enumerate(resultado):
    print(f"VersiÃ³n {i+1}: {texto['generated_text']}")
```

## ğŸ¯ Â¿Por QuÃ© Funciona Tan Bien?

### El Secreto: Modelos Pre-entrenados
- **Millones de parÃ¡metros** entrenados en enormes datasets
- **Transfer Learning**: Conocimiento general aplicado a tareas especÃ­ficas
- **Fine-tuning**: AdaptaciÃ³n a dominios especÃ­ficos

### Ventajas de Hugging Face
- âœ… **Simplicidad**: Una lÃ­nea de cÃ³digo para tareas complejas
- âœ… **Variedad**: Miles de modelos disponibles
- âœ… **Comunidad**: Modelos compartidos y mejorados constantemente
- âœ… **Flexibilidad**: Desde uso bÃ¡sico hasta personalizaciÃ³n avanzada

## ğŸ® PreparaciÃ³n para los Retos

### InstalaciÃ³n RÃ¡pida
```bash
pip install transformers torch datasets evaluate
```

### Estructura Mental para los Retos
1. **Identifica el problema** â†’ Â¿QuÃ© tarea NLP necesito?
2. **Elige el pipeline** â†’ Â¿CuÃ¡l es el mÃ¡s adecuado?
3. **Experimenta** â†’ Prueba con diferentes textos
4. **Optimiza** â†’ Ajusta parÃ¡metros y modelos
5. **EvalÃºa** â†’ Â¿Funciona bien para mi caso de uso?

## ğŸ† Â¡Listos para el Primer Reto!

Ahora que hemos visto la magia en acciÃ³n, es hora de crear nuestro primer proyecto real: **un detector de emociones para redes sociales**.

**Â¿El objetivo?** Ayudar a una empresa a monitorizar la percepciÃ³n de su marca en Twitter.

[ğŸ‘‰ Ir al Reto 1: Detector de Emociones](02_reto1_sentimientos.md)

---

## ğŸ“š Recursos Adicionales

- [DocumentaciÃ³n oficial de Transformers](https://huggingface.co/docs/transformers)
- [Hugging Face Model Hub](https://huggingface.co/models)
- [Curso completo de NLP](https://huggingface.co/learn/nlp-course)
