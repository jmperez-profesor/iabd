---
title: Tasks de Hugging face relacionadas con la Visi贸n por computador
description: Apuntes, pr谩cticas, ejercicio del curso de especializaci贸n en IA y Big Data. 
---

## Objetivos

- Diferenciar qu茅 es un "task" en Machine Learning seg煤n Hugging Face.
- Aprender los conceptos y ejemplos de estimaci贸n de profundidad, clasificaci贸n y segmentaci贸n de im谩genes.
- Probar ejemplos pr谩cticos con pipelines de Hugging Face.

Hugging Face es el portal para todas las tareas de aprendizaje autom谩tico. Aqu铆 encontraremos todo lo necesario para empezar con una tarea: demostraciones, casos de uso, modelos, conjuntos de datos y mucho m谩s.

# 驴Qu茅 es un task?

Un "task" en Hugging Face describe el tipo de problema que un modelo puede resolver.
Permite buscar, probar y reutilizar modelos seg煤n la tarea (task) deseada.

![Tasks (tareas) en Hugging Face](./img/01hf-tasks.png)
*Tasks (tareas) en Hugging Face*

# Uso de Hugging Face para tareas de Visi贸n por Computadora

Hugging Face tambi茅n proporciona una amplia colecci贸n de modelos preentrenados para tareas de visi贸n artificial. Con todos estos modelos alojados previamente entrenados, podemos crear aplicaciones interesantes que detectan objetos en im谩genes, la edad de una persona y m谩s. En este tema, aprenderemos a realizar las primeras cuatro tareas utilizando modelos de Hugging Face. 

## 1. Clasificaci贸n de Im谩genes (Image Classification)

La clasificaci贸n de im谩genes es una tarea de visi贸n artificial que implica categorizar o etiquetar una imagen en una o varias clases o categor铆as predefinidas. El objetivo de la clasificaci贸n de im谩genes es reconocer y asignar la etiqueta m谩s adecuada a una imagen determinada en funci贸n de su contenido. 

![Tasks (tareas) en Hugging Face](./img/image-classification-input_hf.png)

### Ejemplos de aplicaciones:

- Diagn贸stico m茅dico (clasificar radiograf铆as)
- Reconocimiento de objetos
- Clasificaci贸n de productos en e-commerce
- Moderaci贸n de contenido visual

### Modelos disponibles en Hugging Face

Hugging Face ofrece m煤ltiples modelos preentrenados para clasificaci贸n de im谩genes. Algunos destacados:

| Modelo | Arquitectura | Dataset de entrenamiento | Enlace |
|--------|--------------|---------------------------|--------|
| `google/vit-base-patch16-224` | Vision Transformer (ViT) | ImageNet | [ Ver modelo](https://huggingface.co/google/vit-base-patch16-224) |
| `microsoft/resnet-50` | ResNet-50 | ImageNet | [ Ver modelo](https://huggingface.co/microsoft/resnet-50) |
| `facebook/deit-base-patch16-224` | DeiT | ImageNet | [ Ver modelo](https://huggingface.co/facebook/deit-base-patch16-224) |

### "Quick, Draw!" de Google

![](./img/quickdraw1.png)

Este juego fue creado con aprendizaje autom谩tico, donde cuando dibujas algo, una red neuronal intenta adivinar qu茅 est谩s dibujando. Evidentemente, no siempre funciona; pero cuanto m谩s tiempo pasemos jugando, m谩s aprender谩. Destacar que ya reconoce cientos de conceptos y esperan poder a帽adir m谩s en el futuro. El gran objetivo de esta aplicaci贸n, es mostrar un ejemplo de c贸mo se puede usar el aprendizaje autom谩tico de forma divertida. 

**Caracter铆sticas clave**

- **Juego con IA**: El juego es un experimento de aprendizaje autom谩tico. El jugador dibuja y la red neuronal intenta adivinar el dibujo en tiempo real.

- **Aprendizaje continuo**: La IA aprende de cada dibujo, mejorando su capacidad para adivinar correctamente en el futuro. Esto ayuda a Google a recopilar uno de los conjuntos de datos de garabatos m谩s grandes del mundo para la investigaci贸n en aprendizaje autom谩tico.

- **Mec谩nica simple**: El juego es similar al Pictionary. Consiste en seis rondas, y en cada una se nos pide dibujar un objeto diferente en 20 segundos. Al final, podemos ver nuestros dibujos y los resultados.

Podemos acceder al juego en el sitio web oficial: [Web oficial](https://quickdraw.withgoogle.com/). 

**Importancia de los datos - BigData**

Los datos recopilados en el juego "Quick, Draw!" son fundamentales en el 谩mbito del Big Data y el aprendizaje autom谩tico porque conforman el conjunto de datos de garabatos m谩s grande del mundo, esencial para entrenar y mejorar los modelos de inteligencia artificial de Google. 
Su importancia radica en varios puntos clave:

- **Entrenamiento de IA**: Los millones de dibujos (actualmente m谩s de 50 millones en 345 categor铆as) sirven como un vasto corpus de datos para entrenar redes neuronales, ense帽谩ndoles a reconocer e interpretar garabatos de formas muy diversas. La IA aprende a identificar patrones visuales, sin importar el estilo individual del dibujante.

- **Diversidad y variabilidad**: A diferencia de conjuntos de datos de im谩genes tradicionales, los garabatos muestran una enorme variabilidad en c贸mo las personas de diferentes culturas y con distintas habilidades dibujan un mismo objeto. Esta diversidad es crucial para crear modelos de IA m谩s robustos y menos sesgados que puedan funcionar globalmente.

- **Datos en tiempo real y secuenciales**: Los dibujos se capturan como series temporales de posiciones del l谩piz (vectores con marca de tiempo), no solo como im谩genes est谩ticas. Esto permite a los investigadores comprender no solo el resultado final, sino tambi茅n el proceso de dibujo (qu茅 trazo se hizo primero, en qu茅 direcci贸n), lo cual es valioso para desarrollar modelos de IA m谩s avanzados, como el modelo Sketch-RNN.

- **Investigaci贸n abierta**: Google ha hecho p煤blico este conjunto de datos para que investigadores de todo el mundo puedan utilizarlo en sus propios proyectos y estudios de aprendizaje autom谩tico, fomentando la innovaci贸n en el campo.

- **Ejemplo de gamificaci贸n para la recolecci贸n de datos**: El juego es un excelente ejemplo de c贸mo la gamificaci贸n puede motivar a un gran n煤mero de usuarios a generar datos valiosos de forma divertida y a gran escala, un desaf铆o com煤n en el Big Data

[Datos de entrenamiento](https://quickdraw.withgoogle.com/data)

![](./img/quickdraw2.webp)

En esta p谩gina podemos ver, en el momento en el que se redactaban estos apuntes, 126.372 dibujos de pelotas de baloncesto hechas por personales reales...en Internet. Incluso, podemos ver los trazos que han realizado estas personas hasta que el modelo ha sido capaz de adivinar el dibujo. 
Destacar la importancia del Big Data, ya que, los datos de entrenamiento son muy importantes para cualquier modelo de aprendizaje. 

[Datos de entrenamiento para la pelota de baloncesto](https://quickdraw.withgoogle.com/data/basketball)

![](./img/data_basketball_quickdraw.png)

### Desarrollo de nuestro propio Pictionary con Gradio

Vamos a crear una aplicaci贸n web con Gradio que use el modelo creado en una sesi贸n anterior: [omarques/autotrain-dogs-and-cats-1527055142](https://huggingface.co/omarques/autotrain-dogs-and-cats-1527055142)

Ejemplo de aplicaci贸n Gradio con una imagen de entrada y un Label como componente de salida:
![](./img/dogs_vs_cats1.png)

Etiquetado de la imagen de entrada:
![](./img/dogs_vs_cats2.png)

### 2. Detecci贸n de objetos 

![Tasks - Object detection in Hugging Face](./img/object-detecction-hf.png)

La detecci贸n de objetos predice la distancia de cada p铆xel respecto a la c谩mara usando solo una imagen. Es una t茅cnica fundamental en visi贸n computacional que permite identificar y localizar instancias de objetos definidos dentro de im谩genes. Es ampliamente utilizada en aplicaciones como conducci贸n aut贸noma, seguimiento de objetos en deportes, b煤squeda de im谩genes y conteo de objetos en diferentes escenarios. 

Hugging Face alberga varios modelos que han sido entrenados previamente para detectar objetos en im谩genes. Podemos ver una lista de modelos en https://huggingface.co/models?pipeline_tag=object-detection&sort=trending 
Ver figura siguiente:

![](./img/tasks_hf_object_detection.png)

Ejemplo del facebook/detr-resnet-50 para la detecci贸n de objetos:

![](./img/tasks_hf_object_detection_example.png)

Podemos probar el modelo directamente en Hugging Face utilizando la API de inferencia alojada en Hugging Face. Para ello, usaremos una imagen de una oficina con algunas mujeres (https://en.wikipedia.org/wiki/Office#/media/File:Good_Smile_Company_offices_ladies.jpg;). 

![](./img/Good_Smile_Company_offices_ladies.jpg)

Al arrastrar y soltar la imagen en la secci贸n "Inference API" alojada en la p谩gina del modelo en Hugging Face, veremos la lista de objetos detectados, as铆 como sus probabilidades correspondientes:

Objetos detectados en la imagen y sus probabilidades correspondientes:
![](./img/object_detection_good_Smile_Company_offices_ladies.png)

Al pasar el rat贸n por encima del nombre de un objeto detectado, la imagen resalta el cuadro delimitador del objeto seleccionado.

## Algunos modelos disponibles en Hugging Face

Hugging Face ofrece modelos preentrenados que permiten realizar detecci贸n de objetos sin necesidad de entrenamiento adicional.

| Modelo | Arquitectura | Dataset | Enlace |
|--------|--------------|---------|--------|
| `facebook/detr-resnet-50` | DETR (DEtection TRansformer) | COCO |  Ver modelo |
| `hustvl/yolos-small` | YOLOS (Vision Transformer) | COCO |  Ver modelo |

## Principales Aplicaciones

- **Conducci贸n aut贸noma:** Los coches sin conductor usan la detecci贸n de objetos para reconocer peatones, bicicletas, sem谩foros y se帽ales de tr谩fico, ayudando a la toma de decisiones en tiempo real.
- **Seguimiento en deportes:** En partidos de f煤tbol o tenis se rastrea el bal贸n o los jugadores para mejorar el arbitraje y el an谩lisis estad铆stico.
- **B煤squeda de im谩genes:** Los tel茅fonos inteligentes permiten buscar lugares u objetos directamente en internet mediante la detecci贸n de entidades en fotos.
- **Conteo de objetos:** La detecci贸n ayuda a contar existencias en almacenes, tiendas, o personas en eventos.

## M茅tricas de Evaluaci贸n

- **Precisi贸n media promedio (AP):** rea bajo la curva de precisi贸n versus recall para cada clase.
- **mAP (mean Average Precision):** Promedio de AP en todas las clases.
- **AP伪:** Precisi贸n promedio seg煤n el umbral de IoU (por ejemplo, AP50 muestra AP cuando el IoU es >0,5).


### 3. Segmentaci贸n de im谩genes (Image segmentation)

Otra t茅cnica de visi贸n por computadora com煤nmente utilizada es la segmentaci贸n de im谩genes. La segmentaci贸n de im谩genes es una t茅cnica que consiste en separar una imagen en varios segmentos o regiones. Cada segmento corresponde a un objeto de inter茅s particular. Con la segmentaci贸n de im谩genes, podemos analizar una imagen y extraer informaci贸n valiosa de ella. 

Algunos de sus usos son: 

- **Im谩genes m茅dicas**: se utilizan para identificar y segmentar tumores en resonancias magn茅ticas o tomograf铆as computarizadas 
- **Detecci贸n y reconocimiento de objetos**: al igual que la detecci贸n de objetos que hemos visto anteriormente, tambi茅n podemos utilizar la segmentaci贸n de im谩genes para identificar y localizar objetos en una imagen 
- **Procesamiento de documentos**: se utiliza para segmentar regiones de texto en documentos escaneados 
- **Biometr铆a**: se utiliza para identificar y localizar rostros en im谩genes o fotogramas de v铆deo 

Hugging Face contiene varios modelos de segmentaci贸n de im谩genes que podemos utilizar. Uno de ellos es el modelo "SegFormer model fine-tuned on ADE20k" (https://huggingface.co/nvidia/segformer-b0-finetuned-ade-512-512). 
La siguente imagen muestra el modelo SegFormer ajustado en el modelo ADE20k en el sitio web de Hugging Face:

![](./img/tasks_image_segmentation_ade20k_hf.png)

Para probar el modelo de segmentaci贸n, usaremos una imagen del Taj Mahal. La arrastraremos y la soltaremos en la secci贸n de "Hosted inference API" alojada en la p谩gina de Hugging Face:

Imagen del Taj Mahal (Fuente: https://mng.bz/5vzD)
![](./img/Taj_Mahal_Agra,_India_edit3.jpg)

Resultado de la segmentaci贸n de im谩genes utilizando una imagen del Taj Mahal:
![](./img/tasks_image_segmentation_taj_mahal_result.png)

Como podomos ver en el resultado, el modelo puede detectar diferentes objetos (como edificios, cielos, 谩rboles, etc.) en la imagen y resaltar los diversos segmentos en la imagen. De hecho, podemos pasar el rat贸n sobre las diversas etiquetas segmentadas y la imagen resaltar谩 dicha etiqueta seleccionada. 

#### 3.1. Uso del modelo con pipeline

Como siempre, queremos poder usar el modelo mediante programaci贸n. Primero, cargamos el modelo y luego verificamos cu谩ntos objetos puede detectar el modelo. La forma m谩s f谩cil de usar el modelo es usar un pipeline  de la librer铆a transformer: 
```python
from transformers import pipeline 
  
segmentation = pipeline("image-segmentation",  
               model="nvidia/segformer-b0-finetuned-ade-512-512") 
  
segmentation.model.config.id2label
```
Estos son los primeros y 煤ltimos cinco objetos que puede detectar (el modelo puede detectar un total de 150 objetos): 
```json
{0: 'wall', 
 1: 'building', 
 2: 'sky', 
 3: 'floor', 
 4: 'tree', 
 ... 
 145: 'shower', 
 146: 'radiator', 
 147: 'glass', 
 148: 'clock', 
 149: 'flag'} 
```
Para este ejemplo, usaremos una imagen de [](https://unsplash.com/photos/EC_GhFRGTAY) para descubrir los distintos segmentos de la imagen. 

En la siguiente figura vemos a un hombre y a un avi贸n que vuela por encima. Fuente: [](https://unsplash.com/photos/EC_GhFRGTAY)


### 4. Estimaci贸n de Profundidad (Depth Estimation)
- **Definici贸n**: Predice la distancia de cada p铆xel respecto a la c谩mara usando solo una imagen.
- **Aplicaciones**: Rob贸tica, realidad aumentada, veh铆culos aut贸nomos, etc.
- **Modelos populares**: DPT, MiDaS

```python {hl_lines="5 7" linenums="1"} 
# Utiliza el pipeline:

from transformers import pipeline

depth = pipeline("depth-estimation", model="Intel/zoedepth-nyu-kitti")

result = depth("ruta_o_url_imagen")

```
### 3. Segmentaci贸n de Im谩genes (Image Segmentation)
- **Definici贸n**: Clasifica cada p铆xel de la imagen
- **Tipos**: Sem谩ntica (por clase) vs Instancia (por objeto individual)
- **Aplicaciones**: Medicina, conducci贸n aut贸noma, edici贸n de im谩genes
- **Modelos populares**: SegFormer, Mask2Former




