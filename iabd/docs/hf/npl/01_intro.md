---
title: Tasks NLP con los Transformers y pipelines de Hugging Face - IntroducciÃ³n
description: Apuntes, prÃ¡cticas, ejercicio del curso de especializaciÃ³n en IA y Big Data. 
---

# ğŸ”¥ IntroducciÃ³n: El Poder de los Transformers

## ğŸ¬ Demo en Vivo: "5 LÃ­neas de cÃ³digo sencillas"

### InstalaciÃ³n RÃ¡pida
```bash
pip install transformers torch
```
### Ejemplo sencillo âœ¨

```python {hl_lines="1 4 5" linenums="1"} 
from transformers import pipeline

# Â¡Una lÃ­nea para crear un analizador de sentimientos!
classifier = pipeline("sentiment-analysis")
result = classifier("I loved Star Wars so much!")
print(result)  # [{'label': 'POSITIVE', 'score': 0.9998}]
```
Destacar el siguiente mensaje:
```bash
No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).
```
**Â¿QuÃ© acabamos de hacer?** En 3 lÃ­neas hemos creado un sistema de IA que entiende emociones humanas. 

### ğŸ¯ Tareas NLP Principales

| Tarea | Pipeline | Ejemplo de Uso |
|-------|----------|----------------|
| **AnÃ¡lisis de Sentimientos** | `sentiment-analysis` | Redes sociales, reviews |
| **ClasificaciÃ³n de Texto** | `text-classification` | Categorizar noticias, emails |
| **GeneraciÃ³n de Texto** | `text-generation` | Chatbots, escritura creativa |
| **TraducciÃ³n** | `translation` | Apps multiidioma |
| **Resumen** | `summarization` | ResÃºmenes automÃ¡ticos |

### ğŸ—ï¸ Arquitectura Simplificada

```
Texto de Entrada â†’ TokenizaciÃ³n â†’ Modelo Transformer â†’ Post-procesado â†’ Resultado
```

## ğŸš€ Demo Interactiva: 

### Experimento 1: Sentimientos Multiidioma
```python {hl_lines="1" linenums="1"} 
classifier = pipeline("sentiment-analysis")

textos = [
    "I love this workshop!",
    "Este taller es aburrido",
    "Je suis trÃ¨s content",
    "ğŸ˜ğŸ‰âœ¨"
]

for texto in textos:
    resultado = classifier(texto)
    print(f"{texto} â†’ {resultado[0]['label']} ({resultado[0]['score']:.2f})")
```
**Â¿Funciona correctamente?**

No funciona correctamente porque usamos `pipeline("sentiment-analysis")` sin especificar modelo, asÃ­ que se carga el modelo por defecto de la librerÃ­a, que suele ser un DistilBERT entrenado para sentimiento en inglÃ©s (positivo/negativo) sobre un dataset como SSTâ€‘2. La frase "I love this workshop!" probablemente se clasifique bien, pero "Este taller es aburrido" o "Je suis trÃ¨s content" pueden recibir resultados menos fiables porque el modelo estÃ¡ optimizado para inglÃ©s. Los emojis pueden interpretarse, pero de forma limitada.

Vamos a modificar el cÃ³digo especificando, por ejemplo, el modelo [`tabularisai/multilingual-sentiment-analysis`](https://huggingface.co/tabularisai/multilingual-sentiment-analysis) (model="tabularisai/multilingual-sentiment-analysis"). Un modelo entrenado explÃ­citamente para anÃ¡lisis de sentimiento multilingÃ¼e, pensado para manejar varios idiomas, incluido el espaÃ±ol. 

Modificamos el cÃ³digo y volvemos a probar.

```python {hl_lines="1" linenums="3 4"}
from transformers import pipeline

classifier = pipeline("sentiment-analysis", 
                        model="tabularisai/multilingual-sentiment-analysis")

textos = [
    "I love this workshop!",
    "Este taller es aburrido",
    "Je suis trÃ¨s content",
    "ğŸ˜ğŸ‰âœ¨"
]

for texto in textos:
    resultado = classifier(texto)
    print(f"{texto} â†’ {resultado[0]['label']} ({resultado[0]['score']:.2f})")

#I love this workshop! â†’ Positive (0.52)
#Este taller es aburrido â†’ Negative (0.73)
#Je suis trÃ¨s content â†’ Positive (0.88)
#ğŸ˜ğŸ‰âœ¨ â†’ Neutral (0.34)
```

```bash
config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 851/851 [00:00<00:00, 9.89MB/s]
model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 541M/541M [01:10<00:00, 7.64MB/s]
tokenizer_config.json: 1.20kB [00:00, 2.69MB/s]
vocab.txt: 996kB [00:00, 9.65MB/s]
tokenizer.json: 2.92MB [00:00, 25.5MB/s]
special_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
``` 

### Experimento 2: GeneraciÃ³n InstantÃ¡nea

Otra tarea comÃºn de NLP es la generaciÃ³n de textos. La tarea de generaciÃ³n de texto implica la creaciÃ³n de texto nuevo, coherente y contextualmente relevante basado en un mensaje o entrada determinados. Esta tarea aprovecha los modelos de aprendizaje automÃ¡tico, particularmente los basados en el aprendizaje profundo (deep learning) y las redes neuronales, para producir texto similar al humano. En el siguiente fragmento de cÃ³digo, se muestra cÃ³mo utilizar el modelo openai-community/gpt2 para generar un pÃ¡rrafo de texto basado en una frase inicial:
```python {hl_lines="1" linenums="1"}
from transformers import pipeline 
  
generator = pipeline("text-generation",  
                     model="openai-community/gpt2") 

generator("In this course, we will teach you how to")
```
Genera la siguiente salida (tengamos en cuenta que la salida serÃ¡ diferente cada vez que se ejecute el fragmento de cÃ³digo): 
```bash
[{'generated_text': 'In this course, we will teach you how to build the best online games or use it to build your own. After this, this course covers: 1) how to make awesome games in Google Play and 2) how to develop a game based on'}] 
``` 
Podemos controlar la salida utilizando los parÃ¡metros `max_length` (el nÃºmero mÃ¡ximo de tokens en el texto generado) y `num_return_sequences` (nÃºmero de pÃ¡rrafos generados): 

```python {hl_lines="1" linenums="1"}
generator = pipeline("text-generation", model="openai-community/gpt2")

prompt = "In the future, artificial intelligence"

resultado = generator(prompt, max_length=50, num_return_sequences=2)

for i, texto in enumerate(resultado):
    print(f"VersiÃ³n {i+1}: {texto['generated_text']}")
```

## ğŸ¯ Â¿Por QuÃ© funciona tan bien?

### El Secreto: Modelos Pre-entrenados
- **Millones de parÃ¡metros** entrenados en enormes datasets
- **Transfer Learning**: Conocimiento general aplicado a tareas especÃ­ficas
- **Fine-tuning**: AdaptaciÃ³n a dominios especÃ­ficos

### Ventajas de Hugging Face
- âœ… **Simplicidad**: Una lÃ­nea de cÃ³digo para tareas complejas
- âœ… **Variedad**: Miles de modelos disponibles
- âœ… **Comunidad**: Modelos compartidos y mejorados constantemente
- âœ… **Flexibilidad**: Desde uso bÃ¡sico hasta personalizaciÃ³n avanzada

## ğŸ® PreparaciÃ³n para los retos

### Estructura Mental para los Retos
1. **Identifica el problema** â†’ Â¿QuÃ© tarea NLP necesito?
2. **Elige el pipeline** â†’ Â¿CuÃ¡l es el mÃ¡s adecuado?
3. **Experimenta** â†’ Prueba con diferentes textos
4. **Optimiza** â†’ Ajusta parÃ¡metros y modelos
5. **EvalÃºa** â†’ Â¿Funciona bien para mi caso de uso?

## ğŸ† Â¡Listos para el primer reto!

Ahora que hemos visto algunos modelos de NPL en acciÃ³n, es hora de crear nuestro primer proyecto real: **un detector de emociones para redes sociales**.

**Â¿El objetivo?** Ayudar a una empresa a monitorizar la percepciÃ³n de su marca en X.

[ğŸ‘‰ Ir al Reto 1: Detector de Emociones](02_reto1_sentimientos.md)

---

## ğŸ“š Recursos Adicionales

- [DocumentaciÃ³n oficial de Transformers](https://huggingface.co/docs/transformers)
- [Hugging Face Model Hub](https://huggingface.co/models)
- [Curso completo de NLP](https://huggingface.co/learn/nlp-course)
