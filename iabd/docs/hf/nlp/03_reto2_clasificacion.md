---
title: Tasks NLP con los Transformers y pipelines de Hugging Face - Reto 2
description: Apuntes, pr√°cticas, ejercicio del curso de especializaci√≥n en IA y Big Data. 
---

# üèÜ Reto 2: Clasificador Inteligente de Noticias

**‚è±Ô∏è Tiempo:** 30 minutos  
**üéØ Nivel:** Intermedio  
**üöÄ Objetivo:** Construir un sistema de categorizaci√≥n autom√°tica de noticias

## üé¨ Contexto y Motivaci√≥n (5 min)

### El problema real
Un peri√≥dico digital recibe **500+ art√≠culos diarios** de diferentes fuentes. Su equipo editorial necesita:

- Clasificar autom√°ticamente las noticias por categor√≠as
- Priorizar noticias importantes para la portada
- Detectar noticias duplicadas o similares
- Organizar el contenido para diferentes secciones

### ¬øPor qu√© es crucial?
- **Ahorro de tiempo:** De 4 horas manuales a 10 minutos autom√°ticos
- **Consistencia:** Clasificaci√≥n uniforme sin sesgos humanos
- **Escalabilidad:** Manejar vol√∫menes masivos de informaci√≥n
- **Personalizaci√≥n:** Contenido relevante para cada usuario

## üß† Teor√≠a Just-in-Time (10 min)

### Clasificaci√≥n de Texto vs An√°lisis de Sentimientos

| Aspecto | An√°lisis de Sentimientos | Clasificaci√≥n de Texto |
|---------|-------------------------|------------------------|
| **Objetivo** | Detectar emociones | Categorizar por tema |
| **Clases** | Positivo/Negativo/Neutral | Deportes/Pol√≠tica/Tecnolog√≠a/etc |
| **Complejidad** | 2-3 categor√≠as | 10+ categor√≠as |
| **Aplicaciones** | Redes sociales, reviews | Noticias, emails, documentos |

### Modelos Especializados

```python {linenums="1"}
# Modelos populares para clasificaci√≥n
modelos_clasificacion = {
    "noticias_espa√±ol": "bertin-project/bertin-roberta-base-spanish",
    "noticias_general": "facebook/bart-large-mnli",
    "multiidioma": "microsoft/DialoGPT-medium",
    "zero_shot": "facebook/bart-large-mnli",  # ¬°Sin entrenamiento previo!
    "zero_shot" : "MoritzLaurer/mDeBERTa-v3-base-mnli-xnli" # Admite el idioma espa√±ol 
}
```

### Zero-Shot Classification: Un poco de "magia"

```python {linenums="1" hl_lines="3"}
from transformers import pipeline
# ¬°Clasificar SIN entrenar el modelo!
classifier = pipeline("zero-shot-classification")
texto = "El Real Madrid gan√≥ 3-1 al Barcelona en el Cl√°sico"
categorias = ["deportes", "pol√≠tica", "tecnolog√≠a", "econom√≠a"]

resultado = classifier(texto, categorias)
print(resultado)
# Resultado esperado: "deportes" deber√≠a de tener alta confianza
# Resultado obtenido: "pol√≠tica" con alta confianza
```
```bash
No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).
Using a pipeline without specifying a model name and revision in production is not recommended.
Device set to use cpu
```
```json
{
    'sequence': 'El Real Madrid gan√≥ 3-1 al Barcelona en el Cl√°sico', 
    'labels': ['pol√≠tica', 'econom√≠a', 'deportes', 'tecnolog√≠a'], 
    'scores': [0.5234475135803223, 0.18149752914905548, 0.15290531516075134, 0.14214962720870972]
    }
```
**¬øFunciona?** 

No funciona por c√≥mo funciona realmente la **clasificaci√≥n zero-shot** con modelos **NLI** como `facebook/bart-large-mnli`: el modelo no ‚Äúentiende‚Äù las etiquetas como humanos, sino que compara texto y etiqueta a trav√©s de frases en ingl√©s, y ah√≠ se le cuela el sesgo.‚Äã

1. C√≥mo decide el modelo en zero‚Äëshot

El `pipeline("zero-shot-classification")` con **BART‚ÄëMNLI** hace, de forma simplificada, algo as√≠ para cada etiqueta:‚Äã
- Construye una hip√≥tesis tipo:

    - ‚ÄúThis text is about pol√≠tica.‚Äù
    - ‚ÄúThis text is about deportes.‚Äù
    
- Pasa `(premisa = tu texto, hip√≥tesis) al modelo NLI (entailment / contradiction / neutral).
- Convierte esos *scores* en probabilidades y se queda con la etiqueta cuya hip√≥tesis tiene mayor probabilidad de *‚Äúentailment‚Äù* (que el texto implique esa etiqueta).

No usa un diccionario sem√°ntico ni sabe que ‚ÄúReal Madrid‚Äù y ‚ÄúBarcelona‚Äù son clubes de f√∫tbol; solo ve que ciertas palabras coocurren m√°s a menudo con ‚Äúpol√≠tica‚Äù que con ‚Äúdeportes‚Äù en sus datos de entrenamiento, o que la frase **‚Äúis about pol√≠tica‚Äù** le parece m√°s probable en general.‚Äã

2. Problemas concretos de nuestro caso

Algunos factores que hacen que gane ‚Äúpol√≠tica‚Äù:

- El modelo es **ingl√©s‚Äëc√©ntrico**: est√° entrenado principalmente con datos y plantillas en ingl√©s; al ver etiquetas en espa√±ol, su comportamiento es menos fiable.‚Äã
- Las etiquetas son palabras muy generales: ‚Äúpol√≠tica‚Äù, ‚Äúeconom√≠a‚Äù, ‚Äúdeportes‚Äù, ‚Äútecnolog√≠a‚Äù. La diferencia sem√°ntica en el **embedding** de la hip√≥tesis puede no ser tan clara, y el modelo puede haber visto muchas veces ‚ÄúThis text is about politics‚Äù en sus datos de preentrenamiento, lo que le da una especie de ‚Äúprioridad‚Äù a favor de pol√≠tica.‚Äã
- El texto est√° en espa√±ol: entiende algo (por contexto multiling√ºe parcial), pero la alineaci√≥n entre texto espa√±ol y etiquetas espa√±olas no es perfecta.

El resultado que vemos:
```python
'labels': ['pol√≠tica', 'econom√≠a', 'deportes', 'tecnolog√≠a'],
'scores': [0.52, 0.18, 0.15, 0.14]
```
indica exactamente eso: para el modelo, ‚Äúes sobre pol√≠tica‚Äù es ligeramente m√°s plausible que ‚Äúes sobre deportes‚Äù, aunque para nosotros sea evidente lo contrario.

En resumen, gana ‚Äúpol√≠tica‚Äù porque el modelo compara nuestro texto con hip√≥tesis generadas a partir de las etiquetas, en un espacio **NLI** centrado en ingl√©s, y en ese espacio la hip√≥tesis ‚Äúes pol√≠tica‚Äù le resulta ligeramente m√°s plausible que ‚Äúes deportes‚Äù. No es un ‚Äúerror l√≥gico‚Äù del programa, sino una limitaci√≥n del modelo y de c√≥mo se formulan las etiquetas en zero‚Äëshot.

Vamos a modificar el ejemplo seleccionando un modelo que admite Zero-shot y el idioma espa√±ol. El modelo es [`MoritzLaurer/mDeBERTa-v3-base-mnli-xnli`](
https://huggingface.co/MoritzLaurer/mDeBERTa-v3-base-mnli-xnli)

```python {linenums="1" hl_lines="3"}
from transformers import pipeline
# ¬°Clasificar SIN entrenar el modelo!
classifier = pipeline(
    "zero-shot-classification",
    model="MoritzLaurer/mDeBERTa-v3-base-mnli-xnli")
    
texto = "El Real Madrid gan√≥ 3-1 al Barcelona en el Cl√°sico"
categorias = ["deportes", "pol√≠tica", "tecnolog√≠a", "econom√≠a"]

resultado = classifier(texto, categorias)
print(resultado)
# Resultado esperado: "deportes" deber√≠a de tener alta confianza
# Resultado obtenido: "pol√≠tica" con alta confianza
```
```bash
No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).
Using a pipeline without specifying a model name and revision in production is not recommended.
Device set to use cpu
```
```json
{
    'sequence': 'El Real Madrid gan√≥ 3-1 al Barcelona en el Cl√°sico', 
    'labels': ['pol√≠tica', 'econom√≠a', 'deportes', 'tecnolog√≠a'], 
    'scores': [0.5234475135803223, 0.18149752914905548, 0.15290531516075134, 0.14214962720870972]
    }
```

## üíª Implementaci√≥n guiada (10 min)

### Paso 1: Configuraci√≥n y Datos

```python {linenums="1"}
from transformers import pipeline
import pandas as pd
import numpy as np

# Datos de ejemplo (noticias reales simuladas)
noticias = [
    {
        "titulo": "El Real Madrid ficha a Mbapp√© por 180 millones",
        "contenido": "El delantero franc√©s firma por cinco temporadas con el club blanco..."
    },
    {
        "titulo": "Nueva ley de inteligencia artificial aprobada en Europa",
        "contenido": "El Parlamento Europeo aprueba regulaciones para el uso de IA..."
    },
    {
        "titulo": "Bitcoin alcanza nuevo m√°ximo hist√≥rico",
        "contenido": "La criptomoneda supera los 70.000 d√≥lares por primera vez..."
    },
    {
        "titulo": "Descubren nueva especie de dinosaurio en Argentina",
        "contenido": "Paleont√≥logos argentinos encuentran restos de un titanosaurio..."
    },
    {
        "titulo": "Apple presenta el iPhone 16 con IA integrada",
        "contenido": "La nueva generaci√≥n incluye procesador neuronal avanzado..."
    }
]

# Categor√≠as objetivo
categorias = ["deportes", "pol√≠tica", "econom√≠a", "ciencia", "tecnolog√≠a"]
```

### Paso 2: Clasificaci√≥n Zero-Shot

```python {linenums="1"}
# Crear clasificador zero-shot
classifier = pipeline("zero-shot-classification", 
                     model="facebook/bart-large-mnli")

def clasificar_noticia(noticia, categorias):
    """Clasifica una noticia usando zero-shot learning"""
    texto_completo = f"{noticia['titulo']} {noticia['contenido']}"
    resultado = classifier(texto_completo, categorias)
    
    return {
        'titulo': noticia['titulo'],
        'categoria_predicha': resultado['labels'][0],
        'confianza': resultado['scores'][0],
        'todas_las_scores': dict(zip(resultado['labels'], resultado['scores']))
    }

# Clasificar todas las noticias
resultados = []
for noticia in noticias:
    resultado = clasificar_noticia(noticia, categorias)
    resultados.append(resultado)
    
    print(f"üì∞ {resultado['titulo'][:50]}...")
    print(f"üè∑Ô∏è  Categor√≠a: {resultado['categoria_predicha']} ({resultado['confianza']:.2f})")
    print("-" * 60)
```

### Paso 3: An√°lisis Avanzado con M√∫ltiples Categor√≠as

```python {linenums="1"}
def clasificacion_multinivel(noticia, categorias_principales, subcategorias):
    """Clasificaci√≥n jer√°rquica: primero categor√≠a principal, luego subcategor√≠a"""
    
    # Paso 1: Categor√≠a principal
    texto = f"{noticia['titulo']} {noticia['contenido']}"
    resultado_principal = classifier(texto, categorias_principales)
    categoria_principal = resultado_principal['labels'][0]
    
    # Paso 2: Subcategor√≠a (si existe)
    if categoria_principal in subcategorias:
        resultado_sub = classifier(texto, subcategorias[categoria_principal])
        subcategoria = resultado_sub['labels'][0]
    else:
        subcategoria = "general"
    
    return {
        'categoria_principal': categoria_principal,
        'subcategoria': subcategoria,
        'confianza_principal': resultado_principal['scores'][0],
        'ruta_completa': f"{categoria_principal}/{subcategoria}"
    }

# Definir jerarqu√≠a de categor√≠as
categorias_principales = ["deportes", "tecnolog√≠a", "ciencia", "econom√≠a", "pol√≠tica"]
subcategorias = {
    "deportes": ["f√∫tbol", "baloncesto", "tenis", "otros deportes"],
    "tecnolog√≠a": ["inteligencia artificial", "m√≥viles", "software", "hardware"],
    "ciencia": ["medicina", "f√≠sica", "biolog√≠a", "paleontolog√≠a"],
    "econom√≠a": ["criptomonedas", "bolsa", "empresas", "comercio"]
}

# Probar clasificaci√≥n multinivel
for noticia in noticias[:3]:  # Solo las primeras 3 para el ejemplo
    resultado = clasificacion_multinivel(noticia, categorias_principales, subcategorias)
    print(f"üì∞ {noticia['titulo']}")
    print(f"üóÇÔ∏è  Ruta: {resultado['ruta_completa']}")
    print(f"üìä Confianza: {resultado['confianza_principal']:.2f}")
    print("-" * 50)
```

### Paso 4: Sistema de Recomendaci√≥n Simple

```python {linenums="1"}
def recomendar_noticias_similares(noticia_objetivo, todas_las_noticias, top_k=3):
    """Encuentra noticias similares bas√°ndose en la clasificaci√≥n"""
    
    # Clasificar la noticia objetivo
    resultado_objetivo = clasificar_noticia(noticia_objetivo, categorias)
    categoria_objetivo = resultado_objetivo['categoria_predicha']
    
    # Clasificar todas las noticias
    noticias_clasificadas = []
    for noticia in todas_las_noticias:
        if noticia != noticia_objetivo:  # Excluir la noticia objetivo
            resultado = clasificar_noticia(noticia, categorias)
            noticias_clasificadas.append(resultado)
    
    # Filtrar por misma categor√≠a y ordenar por confianza
    similares = [n for n in noticias_clasificadas 
                if n['categoria_predicha'] == categoria_objetivo]
    similares.sort(key=lambda x: x['confianza'], reverse=True)
    
    return similares[:top_k]

# Probar recomendaciones
noticia_test = noticias[0]  # Noticia de f√∫tbol
recomendaciones = recomendar_noticias_similares(noticia_test, noticias)

print(f"üéØ Noticia objetivo: {noticia_test['titulo']}")
print("\nüìã Noticias similares recomendadas:")
for i, rec in enumerate(recomendaciones, 1):
    print(f"{i}. {rec['titulo']}")
    print(f"   Categor√≠a: {rec['categoria_predicha']} ({rec['confianza']:.2f})")
```

## üéØ Experimentaci√≥n Libre (5 min)

### Desaf√≠os para Explorar

1. **Categor√≠as Personalizadas:**
   ```python
   # Prueba con tus propias categor√≠as
   mis_categorias = ["urgente", "no urgente", "entretenimiento", "educativo"]
   ```

2. **Detecci√≥n de Fake News:**
   ```python
   categorias_veracidad = ["noticia real", "posible fake news", "s√°tira"]
   ```

3. **An√°lisis de Sentimiento + Clasificaci√≥n:**
   ```python
   def analisis_completo(noticia):
       # Combinar clasificaci√≥n tem√°tica + an√°lisis de sentimientos
       pass
   ```

### Experimentos Avanzados

```python {linenums="1"}
# 1. Clasificaci√≥n con confianza m√≠nima
def clasificar_con_umbral(noticia, categorias, umbral_confianza=0.7):
    resultado = clasificar_noticia(noticia, categorias)
    if resultado['confianza'] < umbral_confianza:
        return "clasificaci√≥n_incierta"
    return resultado['categoria_predicha']

# 2. Detecci√≥n de noticias at√≠picas
def detectar_noticias_atipicas(noticias, categorias):
    confianzas = []
    for noticia in noticias:
        resultado = clasificar_noticia(noticia, categorias)
        confianzas.append(resultado['confianza'])
    
    umbral_atipico = np.percentile(confianzas, 25)  # 25% m√°s bajas
    return [n for n, c in zip(noticias, confianzas) if c < umbral_atipico]
```

## üèÖ Criterios de √âxito

Al completar este reto, deber√≠as poder:

- ‚úÖ Implementar clasificaci√≥n zero-shot
- ‚úÖ Crear sistemas de clasificaci√≥n jer√°rquica
- ‚úÖ Construir recomendadores simples basados en categor√≠as
- ‚úÖ Manejar m√∫ltiples categor√≠as y subcategor√≠as
- ‚úÖ Evaluar la confianza de las predicciones

## üöÄ Extensiones Opcionales

### Para los m√°s r√°pidos:

1. **Dashboard Interactivo:**
   ```python {linenums="1"}
   import gradio as gr

    # Se asume que ya tienes definida esta funci√≥n y la lista `categorias`
    # def clasificar_noticia(noticia: dict, categorias: list) -> dict:
    #     # devuelve, por ejemplo: {"categoria_predicha": "Pol√≠tica", "confianza": 0.87}
    #     ...
    # categorias = ["Pol√≠tica", "Econom√≠a", "Deportes", "Tecnolog√≠a", "Cultura"]

    def clasificar_noticia_interface(texto_noticia):
        if not texto_noticia.strip():
            return "Por favor, pega una noticia para clasificar.", ""
        resultado = clasificar_noticia({"titulo": "", "contenido": texto_noticia}, categorias)
        categoria = f"Categor√≠a: {resultado['categoria_predicha']}"
        confianza = f"Confianza: {resultado['confianza']:.2f}"
        return categoria, confianza

    with gr.Blocks(title="üì∞ Clasificador de Noticias IA") as demo:
        gr.Markdown("# üì∞ Clasificador de Noticias IA")

        texto_noticia = gr.Textbox(
            label="Pega aqu√≠ tu noticia:",
            lines=10,
            placeholder="Copia y pega el texto completo de la noticia..."
        )

        boton = gr.Button("Clasificar")

        salida_categoria = gr.Markdown()
        salida_confianza = gr.Markdown()

        boton.click(
            fn=clasificar_noticia_interface,
            inputs=texto_noticia,
            outputs=[salida_categoria, salida_confianza],
        )

    if __name__ == "__main__":
        demo.launch()
   ```

2. **API REST Simple:**
   ```python {linenums="1"}
   from flask import Flask, request, jsonify
   
   app = Flask(__name__)
   
   @app.route('/clasificar', methods=['POST'])
   def clasificar_api():
       data = request.json
       resultado = clasificar_noticia(data, categorias)
       return jsonify(resultado)
   ```

3. **An√°lisis de Tendencias:**
   ```python {linenums="1"}
   def analizar_tendencias_diarias(noticias_por_dia):
       """Analiza qu√© categor√≠as son trending cada d√≠a"""
       tendencias = {}
       for dia, noticias in noticias_por_dia.items():
           categorias_dia = [clasificar_noticia(n, categorias)['categoria_predicha'] for n in noticias]
           tendencias[dia] = pd.Series(categorias_dia).value_counts()
       return tendencias
   ```

## üéØ Pr√≥ximo Reto

Has construido un sistema completo de clasificaci√≥n de noticias. 

Para el reto final, vamos a explorar la frontera m√°s emocionante del NLP: **la generaci√≥n de texto creativo**. Crearemos un asistente de escritura que ayude a generar contenido original.

[üëâ Ir al Reto 3: Asistente de Escritura Creativa](04_reto3_generacion.md)

---

## üìö Recursos del Reto

- [Zero-Shot Classification Guide](https://huggingface.co/docs/transformers/tasks/zero_shot_classification)
- [Modelos de Clasificaci√≥n](https://huggingface.co/models?pipeline_tag=zero-shot-classification)
- [BART Model Documentation](https://huggingface.co/facebook/bart-large-mnli)
