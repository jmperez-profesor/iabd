
<!doctype html>
<html lang="es" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Apuntes, pr谩cticas, ejercicio del curso de especializaci贸n en IA y Big Data.">
      
      
      
        <link rel="canonical" href="https://jmperez-profesor.github.io/iabd/hf/Tasks_vc/">
      
      
        <link rel="prev" href="../Ejemplo_gradio/">
      
      
        <link rel="next" href="../Referencias/">
      
      
      <link rel="icon" href="../../images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.23">
    
    
      
        <title>Tasks de Hugging face relacionadas con la Visi贸n por computador - Inteligencia Artificial y Big Data</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="light-green" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#objetivos" class="md-skip">
          Saltar a contenido
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Cabecera">
    <a href="https://jmperez-profesor.github.io/iabd/" title="Inteligencia Artificial y Big Data" class="md-header__button md-logo" aria-label="Inteligencia Artificial y Big Data" data-md-component="logo">
      
  <img src="../../images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Inteligencia Artificial y Big Data
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Tasks de Hugging face relacionadas con la Visi贸n por computador
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="light-green" data-md-color-accent="indigo"  aria-label="Cambiar a modo oscuro"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Cambiar a modo oscuro" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="indigo"  aria-label="Cambiar a modo normal"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Cambiar a modo normal" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="B煤squeda" placeholder="B煤squeda" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Buscar">
        
        <button type="reset" class="md-search__icon md-icon" title="Limpiar" aria-label="Limpiar" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Inicializando b煤squeda
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Pesta帽as" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Introducci贸n

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
    
  
  Hugging Face

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navegaci贸n" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://jmperez-profesor.github.io/iabd/" title="Inteligencia Artificial y Big Data" class="md-nav__button md-logo" aria-label="Inteligencia Artificial y Big Data" data-md-component="logo">
      
  <img src="../../images/logo.png" alt="logo">

    </a>
    Inteligencia Artificial y Big Data
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introducci贸n
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Hugging Face
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Hugging Face
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Ejemplo_gradio/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Gradio
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" checked>
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Tasks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Tasks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Visi贸n por computador
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Visi贸n por computador
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Tabla de contenidos">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Tabla de contenidos
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#objetivos" class="md-nav__link">
    <span class="md-ellipsis">
      Objetivos
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#que-es-un-task" class="md-nav__link">
    <span class="md-ellipsis">
      驴Qu茅 es un task?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#uso-de-hugging-face-para-tareas-de-vision-por-computadora" class="md-nav__link">
    <span class="md-ellipsis">
      Uso de Hugging Face para tareas de Visi贸n por Computadora
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Uso de Hugging Face para tareas de Visi贸n por Computadora">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-clasificacion-de-imagenes-image-classification" class="md-nav__link">
    <span class="md-ellipsis">
      1. Clasificaci贸n de Im谩genes (Image Classification)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Clasificaci贸n de Im谩genes (Image Classification)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ejemplos-de-aplicaciones" class="md-nav__link">
    <span class="md-ellipsis">
      Ejemplos de aplicaciones
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modelos-disponibles-en-hugging-face" class="md-nav__link">
    <span class="md-ellipsis">
      Modelos disponibles en Hugging Face
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quick-draw-de-google" class="md-nav__link">
    <span class="md-ellipsis">
      "Quick, Draw!" de Google
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#desarrollo-de-nuestro-propio-pictionary-con-gradio" class="md-nav__link">
    <span class="md-ellipsis">
      Desarrollo de nuestro propio Pictionary con Gradio
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-deteccion-de-objetos" class="md-nav__link">
    <span class="md-ellipsis">
      2. Detecci贸n de objetos
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Detecci贸n de objetos">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#algunos-modelos-disponibles-en-hugging-face" class="md-nav__link">
    <span class="md-ellipsis">
      Algunos modelos disponibles en Hugging Face
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#principales-aplicaciones" class="md-nav__link">
    <span class="md-ellipsis">
      Principales Aplicaciones
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metricas-de-evaluacion" class="md-nav__link">
    <span class="md-ellipsis">
      M茅tricas de Evaluaci贸n
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-segmentacion-de-imagenes-image-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      3. Segmentaci贸n de im谩genes (Image segmentation)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Segmentaci贸n de im谩genes (Image segmentation)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-uso-del-modelo-con-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      3.1. Uso del modelo con pipeline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-enlazando-con-gradio" class="md-nav__link">
    <span class="md-ellipsis">
      3.2. Enlazando con Gradio
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-estimacion-de-profundidad-depth-estimation" class="md-nav__link">
    <span class="md-ellipsis">
      4. Estimaci贸n de Profundidad (Depth Estimation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#actividades" class="md-nav__link">
    <span class="md-ellipsis">
      Actividades
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Referencias/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Referencias
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Actividades/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Actividades
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h2 id="objetivos">Objetivos</h2>
<ul>
<li>Diferenciar qu茅 es un "task" en Machine Learning seg煤n Hugging Face.</li>
<li>Aprender los conceptos y ejemplos de estimaci贸n de profundidad, clasificaci贸n y segmentaci贸n de im谩genes.</li>
<li>Probar ejemplos pr谩cticos con pipelines de Hugging Face.</li>
</ul>
<p>Hugging Face es el portal para todas las tareas de aprendizaje autom谩tico. Aqu铆 encontraremos todo lo necesario para empezar con una tarea: demostraciones, casos de uso, modelos, conjuntos de datos y mucho m谩s.</p>
<h1 id="que-es-un-task">驴Qu茅 es un task?</h1>
<p>Un "task" en Hugging Face describe el tipo de problema que un modelo puede resolver.
Permite buscar, probar y reutilizar modelos seg煤n la tarea (task) deseada.</p>
<p><img alt="Tasks (tareas) en Hugging Face" src="../img/01hf-tasks.png" />
<em>Tasks (tareas) en Hugging Face</em></p>
<h1 id="uso-de-hugging-face-para-tareas-de-vision-por-computadora">Uso de Hugging Face para tareas de Visi贸n por Computadora</h1>
<p>Hugging Face tambi茅n proporciona una amplia colecci贸n de modelos preentrenados para tareas de visi贸n artificial. Con todos estos modelos alojados previamente entrenados, podemos crear aplicaciones interesantes que detectan objetos en im谩genes, la edad de una persona y m谩s. En este tema, aprenderemos a realizar las primeras cuatro tareas utilizando modelos de Hugging Face. </p>
<h2 id="1-clasificacion-de-imagenes-image-classification">1. Clasificaci贸n de Im谩genes (Image Classification)</h2>
<p>La clasificaci贸n de im谩genes es una tarea de visi贸n artificial que implica categorizar o etiquetar una imagen en una o varias clases o categor铆as predefinidas. El objetivo de la clasificaci贸n de im谩genes es reconocer y asignar la etiqueta m谩s adecuada a una imagen determinada en funci贸n de su contenido. </p>
<p><img alt="Tasks (tareas) en Hugging Face" src="../img/image-classification-input_hf.png" /></p>
<h3 id="ejemplos-de-aplicaciones">Ejemplos de aplicaciones</h3>
<ul>
<li>Diagn贸stico m茅dico (clasificar radiograf铆as)</li>
<li>Reconocimiento de objetos</li>
<li>Clasificaci贸n de productos en e-commerce</li>
<li>Moderaci贸n de contenido visual</li>
</ul>
<h3 id="modelos-disponibles-en-hugging-face">Modelos disponibles en Hugging Face</h3>
<p>Hugging Face ofrece m煤ltiples modelos preentrenados para clasificaci贸n de im谩genes. Algunos destacados:</p>
<table>
<thead>
<tr>
<th>Modelo</th>
<th>Arquitectura</th>
<th>Dataset de entrenamiento</th>
<th>Enlace</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>google/vit-base-patch16-224</code></td>
<td>Vision Transformer (ViT)</td>
<td>ImageNet</td>
<td><a href="https://huggingface.co/google/vit-base-patch16-224"> Ver modelo</a></td>
</tr>
<tr>
<td><code>microsoft/resnet-50</code></td>
<td>ResNet-50</td>
<td>ImageNet</td>
<td><a href="https://huggingface.co/microsoft/resnet-50"> Ver modelo</a></td>
</tr>
<tr>
<td><code>facebook/deit-base-patch16-224</code></td>
<td>DeiT</td>
<td>ImageNet</td>
<td><a href="https://huggingface.co/facebook/deit-base-patch16-224"> Ver modelo</a></td>
</tr>
</tbody>
</table>
<h3 id="quick-draw-de-google">"Quick, Draw!" de Google</h3>
<p><img alt="" src="../img/quickdraw1.png" /></p>
<p>Este juego fue creado con aprendizaje autom谩tico, donde cuando dibujas algo, una red neuronal intenta adivinar qu茅 est谩s dibujando. Evidentemente, no siempre funciona; pero cuanto m谩s tiempo pasemos jugando, m谩s aprender谩. Destacar que ya reconoce cientos de conceptos y esperan poder a帽adir m谩s en el futuro. El gran objetivo de esta aplicaci贸n, es mostrar un ejemplo de c贸mo se puede usar el aprendizaje autom谩tico de forma divertida. </p>
<p><strong>Caracter铆sticas clave</strong></p>
<ul>
<li>
<p><strong>Juego con IA</strong>: El juego es un experimento de aprendizaje autom谩tico. El jugador dibuja y la red neuronal intenta adivinar el dibujo en tiempo real.</p>
</li>
<li>
<p><strong>Aprendizaje continuo</strong>: La IA aprende de cada dibujo, mejorando su capacidad para adivinar correctamente en el futuro. Esto ayuda a Google a recopilar uno de los conjuntos de datos de garabatos m谩s grandes del mundo para la investigaci贸n en aprendizaje autom谩tico.</p>
</li>
<li>
<p><strong>Mec谩nica simple</strong>: El juego es similar al Pictionary. Consiste en seis rondas, y en cada una se nos pide dibujar un objeto diferente en 20 segundos. Al final, podemos ver nuestros dibujos y los resultados.</p>
</li>
</ul>
<p>Podemos acceder al juego en el sitio web oficial: <a href="https://quickdraw.withgoogle.com/">Web oficial</a>. </p>
<p><strong>Importancia de los datos - BigData</strong></p>
<p>Los datos recopilados en el juego "Quick, Draw!" son fundamentales en el 谩mbito del Big Data y el aprendizaje autom谩tico porque conforman el conjunto de datos de garabatos m谩s grande del mundo, esencial para entrenar y mejorar los modelos de inteligencia artificial de Google. 
Su importancia radica en varios puntos clave:</p>
<ul>
<li>
<p><strong>Entrenamiento de IA</strong>: Los millones de dibujos (actualmente m谩s de 50 millones en 345 categor铆as) sirven como un vasto corpus de datos para entrenar redes neuronales, ense帽谩ndoles a reconocer e interpretar garabatos de formas muy diversas. La IA aprende a identificar patrones visuales, sin importar el estilo individual del dibujante.</p>
</li>
<li>
<p><strong>Diversidad y variabilidad</strong>: A diferencia de conjuntos de datos de im谩genes tradicionales, los garabatos muestran una enorme variabilidad en c贸mo las personas de diferentes culturas y con distintas habilidades dibujan un mismo objeto. Esta diversidad es crucial para crear modelos de IA m谩s robustos y menos sesgados que puedan funcionar globalmente.</p>
</li>
<li>
<p><strong>Datos en tiempo real y secuenciales</strong>: Los dibujos se capturan como series temporales de posiciones del l谩piz (vectores con marca de tiempo), no solo como im谩genes est谩ticas. Esto permite a los investigadores comprender no solo el resultado final, sino tambi茅n el proceso de dibujo (qu茅 trazo se hizo primero, en qu茅 direcci贸n), lo cual es valioso para desarrollar modelos de IA m谩s avanzados, como el modelo Sketch-RNN.</p>
</li>
<li>
<p><strong>Investigaci贸n abierta</strong>: Google ha hecho p煤blico este conjunto de datos para que investigadores de todo el mundo puedan utilizarlo en sus propios proyectos y estudios de aprendizaje autom谩tico, fomentando la innovaci贸n en el campo.</p>
</li>
<li>
<p><strong>Ejemplo de gamificaci贸n para la recolecci贸n de datos</strong>: El juego es un excelente ejemplo de c贸mo la gamificaci贸n puede motivar a un gran n煤mero de usuarios a generar datos valiosos de forma divertida y a gran escala, un desaf铆o com煤n en el Big Data</p>
</li>
</ul>
<p><a href="https://quickdraw.withgoogle.com/data">Datos de entrenamiento</a></p>
<p><img alt="" src="../img/quickdraw2.webp" /></p>
<p>En esta p谩gina podemos ver, en el momento en el que se redactaban estos apuntes, 126.372 dibujos de pelotas de baloncesto hechas por personales reales...en Internet. Incluso, podemos ver los trazos que han realizado estas personas hasta que el modelo ha sido capaz de adivinar el dibujo. 
Destacar la importancia del Big Data, ya que, los datos de entrenamiento son muy importantes para cualquier modelo de aprendizaje. </p>
<p><a href="https://quickdraw.withgoogle.com/data/basketball">Datos de entrenamiento para la pelota de baloncesto</a></p>
<p><img alt="" src="../img/data_basketball_quickdraw.png" /></p>
<h3 id="desarrollo-de-nuestro-propio-pictionary-con-gradio">Desarrollo de nuestro propio Pictionary con Gradio</h3>
<p>Vamos a crear una aplicaci贸n web con Gradio que use el modelo creado en una sesi贸n anterior: <a href="https://huggingface.co/omarques/autotrain-dogs-and-cats-1527055142">omarques/autotrain-dogs-and-cats-1527055142</a></p>
<p>Ejemplo de aplicaci贸n Gradio con una imagen de entrada y un Label como componente de salida:
<img alt="" src="../img/dogs_vs_cats1.png" /></p>
<p>Etiquetado de la imagen de entrada:
<img alt="" src="../img/dogs_vs_cats2.png" /></p>
<h2 id="2-deteccion-de-objetos">2. Detecci贸n de objetos</h2>
<p><img alt="Tasks - Object detection in Hugging Face" src="../img/object-detecction-hf.png" /></p>
<p>La detecci贸n de objetos predice la distancia de cada p铆xel respecto a la c谩mara usando solo una imagen. Es una t茅cnica fundamental en visi贸n computacional que permite identificar y localizar instancias de objetos definidos dentro de im谩genes. Es ampliamente utilizada en aplicaciones como conducci贸n aut贸noma, seguimiento de objetos en deportes, b煤squeda de im谩genes y conteo de objetos en diferentes escenarios. </p>
<p>Hugging Face alberga varios modelos que han sido entrenados previamente para detectar objetos en im谩genes. Podemos ver una lista de modelos en [] (https://huggingface.co/models?pipeline_tag=object-detection&amp;sort=trending) </p>
<p>En la figura siguiente podemos visualizar un listado de la categor铆a <em>Object Detection</em>:</p>
<p><img alt="" src="../img/tasks_hf_object_detection.png" /></p>
<p>Ejemplo del <strong>facebook/detr-resnet-50</strong> para la detecci贸n de objetos:</p>
<p><img alt="" src="../img/tasks_hf_object_detection_example.png" /></p>
<p>Podemos probar el modelo directamente utilizando la API de inferencia alojada en Hugging Face. Para ello, usaremos una imagen de una oficina con algunas mujeres <a href="https://en.wikipedia.org/wiki/Office#/media/File:Good_Smile_Company_offices_ladies.jpg;"></a>. </p>
<p><img alt="" src="../img/Good_Smile_Company_offices_ladies.jpg" /></p>
<p>Al arrastrar y soltar la imagen en la secci贸n "Inference API" alojada en la p谩gina del modelo en Hugging Face, veremos la lista de objetos detectados, as铆 como sus probabilidades correspondientes:</p>
<p>Objetos detectados en la imagen y sus probabilidades correspondientes:
<img alt="" src="../img/object_detection_good_Smile_Company_offices_ladies.png" /></p>
<p>Al pasar el rat贸n por encima del nombre de un objeto detectado, la imagen resalta el cuadro delimitador del objeto seleccionado.</p>
<h3 id="algunos-modelos-disponibles-en-hugging-face">Algunos modelos disponibles en Hugging Face</h3>
<p>Hugging Face ofrece modelos preentrenados que permiten realizar detecci贸n de objetos sin necesidad de entrenamiento adicional.</p>
<table>
<thead>
<tr>
<th>Modelo</th>
<th>Arquitectura</th>
<th>Dataset</th>
<th>Enlace</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>facebook/detr-resnet-50</code></td>
<td>DETR (DEtection TRansformer)</td>
<td>COCO</td>
<td> Ver modelo</td>
</tr>
<tr>
<td><code>hustvl/yolos-small</code></td>
<td>YOLOS (Vision Transformer)</td>
<td>COCO</td>
<td> Ver modelo</td>
</tr>
</tbody>
</table>
<h3 id="principales-aplicaciones">Principales Aplicaciones</h3>
<ul>
<li><strong>Conducci贸n aut贸noma:</strong> Los coches sin conductor usan la detecci贸n de objetos para reconocer peatones, bicicletas, sem谩foros y se帽ales de tr谩fico, ayudando a la toma de decisiones en tiempo real.</li>
<li><strong>Seguimiento en deportes:</strong> En partidos de f煤tbol o tenis se rastrea el bal贸n o los jugadores para mejorar el arbitraje y el an谩lisis estad铆stico.</li>
<li><strong>B煤squeda de im谩genes:</strong> Los tel茅fonos inteligentes permiten buscar lugares u objetos directamente en internet mediante la detecci贸n de entidades en fotos.</li>
<li><strong>Conteo de objetos:</strong> La detecci贸n ayuda a contar existencias en almacenes, tiendas, o personas en eventos.</li>
</ul>
<h3 id="metricas-de-evaluacion">M茅tricas de Evaluaci贸n</h3>
<ul>
<li><strong>Precisi贸n media promedio (AP):</strong> rea bajo la curva de precisi贸n versus recall para cada clase.</li>
<li><strong>mAP (mean Average Precision):</strong> Promedio de AP en todas las clases.</li>
<li><strong>AP伪:</strong> Precisi贸n promedio seg煤n el umbral de IoU (por ejemplo, AP50 muestra AP cuando el IoU es &gt;0,5).</li>
</ul>
<h2 id="3-segmentacion-de-imagenes-image-segmentation">3. Segmentaci贸n de im谩genes (Image segmentation)</h2>
<p>Otra t茅cnica de visi贸n por computadora com煤nmente utilizada es la segmentaci贸n de im谩genes. La segmentaci贸n de im谩genes es una t茅cnica que consiste en separar una imagen en varios segmentos o regiones. Cada segmento corresponde a un objeto de inter茅s particular. Con la segmentaci贸n de im谩genes, podemos analizar una imagen y extraer informaci贸n valiosa de ella. </p>
<p>Algunos de sus usos son: </p>
<ul>
<li><strong>Im谩genes m茅dicas</strong>: se utilizan para identificar y segmentar tumores en resonancias magn茅ticas o tomograf铆as computarizadas </li>
<li><strong>Detecci贸n y reconocimiento de objetos</strong>: al igual que la detecci贸n de objetos que hemos visto anteriormente, tambi茅n podemos utilizar la segmentaci贸n de im谩genes para identificar y localizar objetos en una imagen </li>
<li><strong>Procesamiento de documentos</strong>: se utiliza para segmentar regiones de texto en documentos escaneados </li>
<li><strong>Biometr铆a</strong>: se utiliza para identificar y localizar rostros en im谩genes o fotogramas de v铆deo </li>
</ul>
<p>Hugging Face contiene varios modelos de segmentaci贸n de im谩genes que podemos utilizar. Uno de ellos es el modelo "SegFormer model fine-tuned on ADE20k" (https://huggingface.co/nvidia/segformer-b0-finetuned-ade-512-512). 
La siguente imagen muestra el modelo SegFormer ajustado en el modelo ADE20k en el sitio web de Hugging Face:</p>
<p><img alt="" src="../img/tasks_image_segmentation_ade20k_hf.png" /></p>
<p>Para probar el modelo de segmentaci贸n, usaremos una imagen del Taj Mahal. La arrastraremos y la soltaremos en la secci贸n de "Hosted inference API" alojada en la p谩gina de Hugging Face:</p>
<p>Imagen del Taj Mahal (Fuente: https://mng.bz/5vzD)
<img alt="" src="../img/Taj_Mahal_Agra%2C_India_edit3.jpg" /></p>
<p>Resultado de la segmentaci贸n de im谩genes utilizando una imagen del Taj Mahal:
<img alt="" src="../img/tasks_image_segmentation_taj_mahal_result.png" /></p>
<p>Como podomos ver en el resultado, el modelo puede detectar diferentes objetos (como edificios, cielos, 谩rboles, etc.) en la imagen y resaltar los diversos segmentos en la imagen. De hecho, podemos pasar el rat贸n sobre las diversas etiquetas segmentadas y la imagen resaltar谩 dicha etiqueta seleccionada. </p>
<h3 id="31-uso-del-modelo-con-pipeline">3.1. Uso del modelo con pipeline</h3>
<p>Como es habitual, usaremos el modelo mediante programaci贸n. Primero, cargamos el modelo y luego verificamos cu谩ntos objetos puede detectar el modelo. La forma m谩s f谩cil de usar el modelo es usar un pipeline  de la librer铆a transformer: 
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span> 

<span class="n">segmentation</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;image-segmentation&quot;</span><span class="p">,</span>  
               <span class="n">model</span><span class="o">=</span><span class="s2">&quot;nvidia/segformer-b0-finetuned-ade-512-512&quot;</span><span class="p">)</span> 

<span class="n">segmentation</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">id2label</span>
</code></pre></div>
Estos son los primeros y 煤ltimos cinco objetos que puede detectar (el modelo puede detectar un total de 150 objetos): 
<div class="highlight"><pre><span></span><code><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;wall&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;buildi</span><span class="kc">n</span><span class="err">g&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="mi">2</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;sky&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="mi">3</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">fl</span><span class="err">oor&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="mi">4</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">tree</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="err">...</span><span class="w"> </span>
<span class="w"> </span><span class="mi">145</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;shower&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="mi">146</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;radia</span><span class="kc">t</span><span class="err">or&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="mi">147</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;glass&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="mi">148</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;clock&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="mi">149</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">fla</span><span class="err">g&#39;</span><span class="p">}</span><span class="w"> </span>
</code></pre></div>
Para este ejemplo, usaremos una imagen donde vemos a un hombre y a un avi贸n que vuela por encima, para as铆 descubrir los distintos segmentos de dicha imagen: </p>
<p><img alt="" src="../img/photo-1487553333251-6c8e26d3dc2c.avif" /> </p>
<p>Fuente: <a href="https://unsplash.com/photos/EC_GhFRGTAY">https://unsplash.com/photos/EC_GhFRGTAY</a></p>
<p>Para detectar los distintos segmentos de la imagen, pasamos la direcci贸n URL de una imagen al objeto <em>pipeline</em>: 
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>

<span class="hll"><span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://bit.ly/46iDeJQ&#39;</span>
</span>
<span class="hll"><span class="n">results</span> <span class="o">=</span> <span class="n">segmentation</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</span>
<span class="hll"><span class="n">results</span>
</span></code></pre></div></td></tr></table></div>
La salida de la variable <em>results</em> es una lista de diccionarios que contiene detalles de cada uno de los segmentos detectados en la imagen: 
<div class="highlight"><pre><span></span><code><span class="p">[{</span><span class="err">&#39;score&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">No</span><span class="kc">ne</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;label&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;wall&#39;</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;mask&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&lt;PIL.Image.Image</span><span class="w"> </span><span class="err">image</span><span class="w"> </span><span class="err">mode=L</span><span class="w"> </span><span class="err">size=</span><span class="mi">1587</span><span class="err">x</span><span class="mi">2381</span><span class="err">&gt;</span><span class="p">},</span>
<span class="w"> </span><span class="p">{</span><span class="err">&#39;score&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">No</span><span class="kc">ne</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;label&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;buildi</span><span class="kc">n</span><span class="err">g&#39;</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;mask&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&lt;PIL.Image.Image</span><span class="w"> </span><span class="err">image</span><span class="w"> </span><span class="err">mode=L</span><span class="w"> </span><span class="err">size=</span><span class="mi">1587</span><span class="err">x</span><span class="mi">2381</span><span class="err">&gt;</span><span class="p">},</span>
<span class="w"> </span><span class="p">{</span><span class="err">&#39;score&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">No</span><span class="kc">ne</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;label&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;sky&#39;</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;mask&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&lt;PIL.Image.Image</span><span class="w"> </span><span class="err">image</span><span class="w"> </span><span class="err">mode=L</span><span class="w"> </span><span class="err">size=</span><span class="mi">1587</span><span class="err">x</span><span class="mi">2381</span><span class="err">&gt;</span><span class="p">},</span>
<span class="w"> </span><span class="p">{</span><span class="err">&#39;score&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">No</span><span class="kc">ne</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;label&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;perso</span><span class="kc">n</span><span class="err">&#39;</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;mask&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&lt;PIL.Image.Image</span><span class="w"> </span><span class="err">image</span><span class="w"> </span><span class="err">mode=L</span><span class="w"> </span><span class="err">size=</span><span class="mi">1587</span><span class="err">x</span><span class="mi">2381</span><span class="err">&gt;</span><span class="p">},</span>
<span class="w"> </span><span class="p">{</span><span class="err">&#39;score&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">No</span><span class="kc">ne</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;label&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;airpla</span><span class="kc">ne</span><span class="err">&#39;</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;mask&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&lt;PIL.Image.Image</span><span class="w"> </span><span class="err">image</span><span class="w"> </span><span class="err">mode=L</span><span class="w"> </span><span class="err">size=</span><span class="mi">1587</span><span class="err">x</span><span class="mi">2381</span><span class="err">&gt;</span><span class="p">}]</span>
</code></pre></div>
En particular, el elemento <em>mask</em> contiene la m谩scara del segmento detectado. Para ver cada una de las m谩scaras detectadas, recorremos la variable <em>results</em>: </p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
<span class="hll">    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>
</span><span class="hll">    <span class="n">display</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;mask&#39;</span><span class="p">])</span>
</span></code></pre></div></td></tr></table></div>
<p>La figura siguiente muestra las m谩scaras detectadas para <em>person</em> (persona) y <em>airplane</em> (avi贸n):
<img alt="" src="../img/parte_blanca_hombre_avion.jpg" /></p>
<p>M谩scaras para los segmentos <em>person</em> y <em>airplane</em></p>
<p>La parte blanca de la m谩scara representa la parte de la imagen que contiene el segmento de inter茅s. Podemos aplicar la m谩scara sobre la imagen original mediante el siguiente fragmento de c贸digo: </p>
<p><div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">raw</span><span class="p">)</span> 

<span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span> 
    <span class="n">base_image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> 
    <span class="n">mask_image</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;mask&#39;</span><span class="p">]</span> 

    <span class="c1"># Aplica la m谩scara sobre la imagen original</span>
<span class="hll">    <span class="n">base_image</span><span class="o">.</span><span class="n">paste</span><span class="p">(</span><span class="n">mask_image</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask_image</span><span class="p">)</span> 
</span>    <span class="c1">#Imprime la etiqueta del segmento</span>
<span class="hll">    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span> 
</span>    <span class="n">display</span><span class="p">(</span><span class="n">base_image</span><span class="p">)</span> 
</code></pre></div></td></tr></table></div>
La figura siguiente muestra las m谩scaras de <em>person</em> (persona) y <em>airplane</em> (avi贸n) aplicadas sobre la imagen original:
<img alt="" src="../img/mascaras_en_imagen_original.jpg" /></p>
<p>Cuando aplicamos la m谩scara sobre la imagen, observaremos que el segmento de inter茅s est谩 en blanco. Ser铆a m谩s natural invertir esto, es decir, el segmento de inter茅s deber铆a mostrarse mientras que el resto deber铆a estar en blanco. Para hacer esto, puede invertir la m谩scara usando la funci贸n <code>invert()</code> de la clase <code>ImageOps</code> en el paquete <code>PIL</code>. Los siguientes cambios invierten la m谩scara y, a continuaci贸n, la aplican sobre la imagen original: </p>
<p><div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">ImageOps</span> 

<span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span> 
    <span class="n">base_image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> 
    <span class="n">mask_image</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;mask&#39;</span><span class="p">]</span> 

    <span class="n">mask_image</span> <span class="o">=</span> <span class="n">ImageOps</span><span class="o">.</span><span class="n">invert</span><span class="p">(</span><span class="n">mask_image</span><span class="p">)</span>  <span class="c1">#Invierte la m谩scara </span>
<span class="hll">    <span class="n">base_image</span><span class="o">.</span><span class="n">paste</span><span class="p">(</span><span class="n">mask_image</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask_image</span><span class="p">)</span>  <span class="c1">#Aplica la m谩scara sobre la imagen original </span>
</span>    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>  <span class="c1">#Imprime la etiqueta del segmento</span>
<span class="hll">    <span class="n">display</span><span class="p">(</span><span class="n">base_image</span><span class="p">)</span> 
</span></code></pre></div></td></tr></table></div>
La figura siguiente muestra las m谩scaras invertidas para <em>person</em> (persona) y <em>airplane</em> (avi贸n)aplicadas en la imagen original. </p>
<p><img alt="" src="../img/imagenes_mascaras_invertidas.jpg" /></p>
<h3 id="32-enlazando-con-gradio">3.2. Enlazando con Gradio</h3>
<p>En lugar de especificar manualmente la direcci贸n URL de la imagen que queremos usar en el modelo, ser铆a m谩s conveniente crear una interfaz de usuario para que probemos el modelo de segmentaci贸n. Tal y como ya hemos utilizado anteiriormente, vamos a hacer uso del paquete Gradio para crear una interfaz de usuario y luego vincularla a la funci贸n que realiza la segmentaci贸n. </p>
<hr />
<h2 id="4-estimacion-de-profundidad-depth-estimation">4. Estimaci贸n de Profundidad (Depth Estimation)</h2>
<ul>
<li><strong>Definici贸n</strong>: Predice la distancia de cada p铆xel respecto a la c谩mara usando solo una imagen.</li>
<li><strong>Aplicaciones</strong>: Rob贸tica, realidad aumentada, veh铆culos aut贸nomos, etc.</li>
<li><strong>Modelos populares</strong>: DPT, MiDaS</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="c1"># Utiliza el pipeline:</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>

<span class="hll"><span class="n">depth</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;depth-estimation&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;Intel/zoedepth-nyu-kitti&quot;</span><span class="p">)</span>
</span>
<span class="hll"><span class="n">result</span> <span class="o">=</span> <span class="n">depth</span><span class="p">(</span><span class="s2">&quot;ruta_o_url_imagen&quot;</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
<h2 id="actividades">Actividades</h2>
<ol>
<li><strong>Usar un Space de Hugging Face</strong><br />
Utiliza el pipeline:</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>

<span class="n">depth</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;depth-estimation&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;Intel/zoedepth-nyu-kitti&quot;</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">depth</span><span class="p">(</span><span class="s2">&quot;ruta_o_url_imagen&quot;</span><span class="p">)</span>
</code></pre></div>
<ol>
<li><strong>Clasificaci贸n de im谩genes</strong>
Crear un aplicaci贸n con Gradio 
En lugar de especificar manualmente la direcci贸n URL de la imagen que queremos usar en el modelo, ser铆a m谩s conveniente crear una interfaz de usuario para que el usuario pruebe el modelo de segmentaci贸n. Aqu铆, vamos a hacer uso del paquete Gradio para crear una interfaz de usuario y luego vincularla a la funci贸n que realiza la segmentaci贸n. </li>
</ol>
<p>Usa el pipeline:
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;image-classification&quot;</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;ruta_o_url_imagen&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</code></pre></div></p>
<ol>
<li><strong>Avanzado (Optativo): Integrar clasificaci贸n y segmentaci贸n</strong> </li>
</ol>
<p>Ejecuta ambos pipelines y visualiza el resultado conjunto.</p>







  
  






                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Volver al principio
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Pie" >
        
          
          <a href="../Ejemplo_gradio/" class="md-footer__link md-footer__link--prev" aria-label="Anterior: Gradio">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Anterior
              </span>
              <div class="md-ellipsis">
                Gradio
              </div>
            </div>
          </a>
        
        
          
          <a href="../Referencias/" class="md-footer__link md-footer__link--next" aria-label="Siguiente: Referencias">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Siguiente
              </span>
              <div class="md-ellipsis">
                Referencias
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "toc.integrate", "navigation.expand", "navigation.top", "navigation.indexes", "content.tabs.link", "content.code.annotate", "content.code.copy", "navigation.footer"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copiado al portapapeles", "clipboard.copy": "Copiar al portapapeles", "search.result.more.one": "1 m\u00e1s en esta p\u00e1gina", "search.result.more.other": "# m\u00e1s en esta p\u00e1gina", "search.result.none": "No se encontraron documentos", "search.result.one": "1 documento encontrado", "search.result.other": "# documentos encontrados", "search.result.placeholder": "Teclee para comenzar b\u00fasqueda", "search.result.term.missing": "Falta", "select.version": "Seleccionar versi\u00f3n"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>