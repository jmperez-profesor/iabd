
<!doctype html>
<html lang="es" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Apuntes, pr√°cticas, ejercicio del curso de especializaci√≥n en IA y Big Data.">
      
      
      
        <link rel="canonical" href="https://jmperez-profesor.github.io/iabd/hf/Tasks_vc/">
      
      
        <link rel="prev" href="../Ejemplo_gradio/">
      
      
        <link rel="next" href="../Referencias/">
      
      
      <link rel="icon" href="../../images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.23">
    
    
      
        <title>Tasks de Hugging face relacionadas con la Visi√≥n por computador - Inteligencia Artificial y Big Data</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="light-green" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#objetivos" class="md-skip">
          Saltar a contenido
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Cabecera">
    <a href="https://jmperez-profesor.github.io/iabd/" title="Inteligencia Artificial y Big Data" class="md-header__button md-logo" aria-label="Inteligencia Artificial y Big Data" data-md-component="logo">
      
  <img src="../../images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Inteligencia Artificial y Big Data
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Tasks de Hugging face relacionadas con la Visi√≥n por computador
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="light-green" data-md-color-accent="indigo"  aria-label="Cambiar a modo oscuro"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Cambiar a modo oscuro" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="indigo"  aria-label="Cambiar a modo normal"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Cambiar a modo normal" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="B√∫squeda" placeholder="B√∫squeda" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Buscar">
        
        <button type="reset" class="md-search__icon md-icon" title="Limpiar" aria-label="Limpiar" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Inicializando b√∫squeda
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Pesta√±as" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Introducci√≥n

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
    
  
  Hugging Face

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navegaci√≥n" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://jmperez-profesor.github.io/iabd/" title="Inteligencia Artificial y Big Data" class="md-nav__button md-logo" aria-label="Inteligencia Artificial y Big Data" data-md-component="logo">
      
  <img src="../../images/logo.png" alt="logo">

    </a>
    Inteligencia Artificial y Big Data
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introducci√≥n
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Hugging Face
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Hugging Face
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Ejemplo_gradio/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Gradio
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" checked>
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Tasks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Tasks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Visi√≥n por computador
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Visi√≥n por computador
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Tabla de contenidos">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Tabla de contenidos
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#objetivos" class="md-nav__link">
    <span class="md-ellipsis">
      Objetivos
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#que-es-un-task" class="md-nav__link">
    <span class="md-ellipsis">
      ¬øQu√© es un task?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#uso-de-hugging-face-para-tareas-de-vision-por-computadora" class="md-nav__link">
    <span class="md-ellipsis">
      Uso de Hugging Face para tareas de Visi√≥n por Computadora
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Uso de Hugging Face para tareas de Visi√≥n por Computadora">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-clasificacion-de-imagenes-image-classification" class="md-nav__link">
    <span class="md-ellipsis">
      1. Clasificaci√≥n de Im√°genes (Image Classification)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Clasificaci√≥n de Im√°genes (Image Classification)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ejemplos-de-aplicaciones" class="md-nav__link">
    <span class="md-ellipsis">
      Ejemplos de aplicaciones
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modelos-disponibles-en-hugging-face" class="md-nav__link">
    <span class="md-ellipsis">
      Modelos disponibles en Hugging Face
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quick-draw-de-google" class="md-nav__link">
    <span class="md-ellipsis">
      "Quick, Draw!" de Google
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#desarrollo-de-nuestro-propio-pictionary-con-gradio" class="md-nav__link">
    <span class="md-ellipsis">
      Desarrollo de nuestro propio Pictionary con Gradio
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#que-es-una-red-neuronal-convolucional-cnn" class="md-nav__link">
    <span class="md-ellipsis">
      ¬øQu√© es una red neuronal convolucional (CNN)?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#caracteristicas-principales" class="md-nav__link">
    <span class="md-ellipsis">
      Caracter√≠sticas principales
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#aplicaciones-tipicas" class="md-nav__link">
    <span class="md-ellipsis">
      Aplicaciones t√≠picas
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ejemplo-didactico-sencillo" class="md-nav__link">
    <span class="md-ellipsis">
      Ejemplo did√°ctico sencillo
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-deteccion-de-objetos" class="md-nav__link">
    <span class="md-ellipsis">
      2. Detecci√≥n de objetos
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Detecci√≥n de objetos">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#algunos-modelos-disponibles-en-hugging-face" class="md-nav__link">
    <span class="md-ellipsis">
      Algunos modelos disponibles en Hugging Face
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#principales-aplicaciones" class="md-nav__link">
    <span class="md-ellipsis">
      Principales Aplicaciones
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metricas-de-evaluacion" class="md-nav__link">
    <span class="md-ellipsis">
      M√©tricas de Evaluaci√≥n
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ejemplo-de-uso-con-gradio" class="md-nav__link">
    <span class="md-ellipsis">
      Ejemplo de uso con Gradio
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-segmentacion-de-imagenes-image-segmentation" class="md-nav__link">
    <span class="md-ellipsis">
      3. Segmentaci√≥n de im√°genes (Image segmentation)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Segmentaci√≥n de im√°genes (Image segmentation)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-uso-del-modelo-con-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      3.1. Uso del modelo con pipeline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-enlazando-con-gradio" class="md-nav__link">
    <span class="md-ellipsis">
      3.2. Enlazando con Gradio
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#actividades" class="md-nav__link">
    <span class="md-ellipsis">
      Actividades
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Referencias/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Referencias
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Actividades/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Actividades
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h2 id="objetivos">Objetivos</h2>
<ul>
<li>Diferenciar qu√© es un "task" en Machine Learning seg√∫n Hugging Face.</li>
<li>Aprender los conceptos y ejemplos de estimaci√≥n de profundidad, clasificaci√≥n y segmentaci√≥n de im√°genes.</li>
<li>Probar ejemplos pr√°cticos con pipelines de Hugging Face.</li>
</ul>
<p>Hugging Face es el portal para todas las tareas de aprendizaje autom√°tico. Aqu√≠ encontraremos todo lo necesario para empezar con una tarea: demostraciones, casos de uso, modelos, conjuntos de datos y mucho m√°s.</p>
<h1 id="que-es-un-task">¬øQu√© es un task?</h1>
<p>Un "task" en Hugging Face describe el tipo de problema que un modelo puede resolver.
Permite buscar, probar y reutilizar modelos seg√∫n la tarea (task) deseada.</p>
<p><img alt="Tasks (tareas) en Hugging Face" src="../img/01hf-tasks.png" />
<em>Tasks (tareas) en Hugging Face</em></p>
<h1 id="uso-de-hugging-face-para-tareas-de-vision-por-computadora">Uso de Hugging Face para tareas de Visi√≥n por Computadora</h1>
<p>Hugging Face tambi√©n proporciona una amplia colecci√≥n de modelos preentrenados para tareas de visi√≥n artificial. Con todos estos modelos alojados previamente entrenados, podemos crear aplicaciones interesantes que detectan objetos en im√°genes, la edad de una persona y m√°s. En este tema, aprenderemos a realizar las primeras cuatro tareas utilizando modelos de Hugging Face. </p>
<h2 id="1-clasificacion-de-imagenes-image-classification">1. Clasificaci√≥n de Im√°genes (Image Classification)</h2>
<p>La clasificaci√≥n de im√°genes es una tarea de visi√≥n artificial que implica categorizar o etiquetar una imagen en una o varias clases o categor√≠as predefinidas. El objetivo de la clasificaci√≥n de im√°genes es reconocer y asignar la etiqueta m√°s adecuada a una imagen determinada en funci√≥n de su contenido. </p>
<p><img alt="Tasks (tareas) en Hugging Face" src="../img/image-classification-input_hf.png" /></p>
<h3 id="ejemplos-de-aplicaciones">Ejemplos de aplicaciones</h3>
<ul>
<li>Diagn√≥stico m√©dico (clasificar radiograf√≠as)</li>
<li>Reconocimiento de objetos</li>
<li>Clasificaci√≥n de productos en e-commerce</li>
<li>Moderaci√≥n de contenido visual</li>
</ul>
<h3 id="modelos-disponibles-en-hugging-face">Modelos disponibles en Hugging Face</h3>
<p>Hugging Face ofrece m√∫ltiples modelos preentrenados para clasificaci√≥n de im√°genes. Algunos destacados:</p>
<table>
<thead>
<tr>
<th>Modelo</th>
<th>Arquitectura</th>
<th>Dataset de entrenamiento</th>
<th>Enlace</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>google/vit-base-patch16-224</code></td>
<td>Vision Transformer (ViT)</td>
<td>ImageNet</td>
<td><a href="https://huggingface.co/google/vit-base-patch16-224">üîó Ver modelo</a></td>
</tr>
<tr>
<td><code>microsoft/resnet-50</code></td>
<td>ResNet-50</td>
<td>ImageNet</td>
<td><a href="https://huggingface.co/microsoft/resnet-50">üîó Ver modelo</a></td>
</tr>
<tr>
<td><code>facebook/deit-base-patch16-224</code></td>
<td>DeiT</td>
<td>ImageNet</td>
<td><a href="https://huggingface.co/facebook/deit-base-patch16-224">üîó Ver modelo</a></td>
</tr>
</tbody>
</table>
<h3 id="quick-draw-de-google">"Quick, Draw!" de Google</h3>
<p><img alt="" src="../img/quickdraw1.png" /></p>
<p>Este juego fue creado con aprendizaje autom√°tico, donde cuando dibujas algo, una red neuronal intenta adivinar qu√© est√°s dibujando. Evidentemente, no siempre funciona; pero cuanto m√°s tiempo pasemos jugando, m√°s aprender√°. Destacar que ya reconoce cientos de conceptos y esperan poder a√±adir m√°s en el futuro. El gran objetivo de esta aplicaci√≥n, es mostrar un ejemplo de c√≥mo se puede usar el aprendizaje autom√°tico de forma divertida. </p>
<p><strong>Caracter√≠sticas clave</strong></p>
<ul>
<li>
<p><strong>Juego con IA</strong>: El juego es un experimento de aprendizaje autom√°tico. El jugador dibuja y la red neuronal intenta adivinar el dibujo en tiempo real.</p>
</li>
<li>
<p><strong>Aprendizaje continuo</strong>: La IA aprende de cada dibujo, mejorando su capacidad para adivinar correctamente en el futuro. Esto ayuda a Google a recopilar uno de los conjuntos de datos de garabatos m√°s grandes del mundo para la investigaci√≥n en aprendizaje autom√°tico.</p>
</li>
<li>
<p><strong>Mec√°nica simple</strong>: El juego es similar al Pictionary. Consiste en seis rondas, y en cada una se nos pide dibujar un objeto diferente en 20 segundos. Al final, podemos ver nuestros dibujos y los resultados.</p>
</li>
</ul>
<p>Podemos acceder al juego en el sitio web oficial: <a href="https://quickdraw.withgoogle.com/">Web oficial</a>. </p>
<p><strong>Importancia de los datos - BigData</strong></p>
<p>Los datos recopilados en el juego "Quick, Draw!" son fundamentales en el √°mbito del Big Data y el aprendizaje autom√°tico porque conforman el conjunto de datos de garabatos m√°s grande del mundo, esencial para entrenar y mejorar los modelos de inteligencia artificial de Google. 
Su importancia radica en varios puntos clave:</p>
<ul>
<li>
<p><strong>Entrenamiento de IA</strong>: Los millones de dibujos (actualmente m√°s de 50 millones en 345 categor√≠as) sirven como un vasto corpus de datos para entrenar redes neuronales, ense√±√°ndoles a reconocer e interpretar garabatos de formas muy diversas. La IA aprende a identificar patrones visuales, sin importar el estilo individual del dibujante.</p>
</li>
<li>
<p><strong>Diversidad y variabilidad</strong>: A diferencia de conjuntos de datos de im√°genes tradicionales, los garabatos muestran una enorme variabilidad en c√≥mo las personas de diferentes culturas y con distintas habilidades dibujan un mismo objeto. Esta diversidad es crucial para crear modelos de IA m√°s robustos y menos sesgados que puedan funcionar globalmente.</p>
</li>
<li>
<p><strong>Datos en tiempo real y secuenciales</strong>: Los dibujos se capturan como series temporales de posiciones del l√°piz (vectores con marca de tiempo), no solo como im√°genes est√°ticas. Esto permite a los investigadores comprender no solo el resultado final, sino tambi√©n el proceso de dibujo (qu√© trazo se hizo primero, en qu√© direcci√≥n), lo cual es valioso para desarrollar modelos de IA m√°s avanzados, como el modelo Sketch-RNN.</p>
</li>
<li>
<p><strong>Investigaci√≥n abierta</strong>: Google ha hecho p√∫blico este conjunto de datos para que investigadores de todo el mundo puedan utilizarlo en sus propios proyectos y estudios de aprendizaje autom√°tico, fomentando la innovaci√≥n en el campo.</p>
</li>
<li>
<p><strong>Ejemplo de gamificaci√≥n para la recolecci√≥n de datos</strong>: El juego es un excelente ejemplo de c√≥mo la gamificaci√≥n puede motivar a un gran n√∫mero de usuarios a generar datos valiosos de forma divertida y a gran escala, un desaf√≠o com√∫n en el Big Data</p>
</li>
</ul>
<p><a href="https://quickdraw.withgoogle.com/data">Datos de entrenamiento</a></p>
<p><img alt="" src="../img/quickdraw2.webp" /></p>
<p>En esta p√°gina podemos ver, en el momento en el que se redactaban estos apuntes, 126.372 dibujos de pelotas de baloncesto hechas por personales reales...en Internet. Incluso, podemos ver los trazos que han realizado estas personas hasta que el modelo ha sido capaz de adivinar el dibujo. 
Destacar la importancia del Big Data, ya que, los datos de entrenamiento son muy importantes para cualquier modelo de aprendizaje. </p>
<p><a href="https://quickdraw.withgoogle.com/data/basketball">Datos de entrenamiento para la pelota de baloncesto</a></p>
<p><img alt="" src="../img/data_basketball_quickdraw.png" /></p>
<h3 id="desarrollo-de-nuestro-propio-pictionary-con-gradio">Desarrollo de nuestro propio Pictionary con Gradio</h3>
<p>Vamos a desarrollar nuestra propia aplicaci√≥n *Pictionary" con Gradio el cual ha sido extra√≠do del siguiente v√≠deo: <a href="https://www.youtube.com/watch?v=LS9Y2wDVI0k"></a></p>
<p>Todos los ficheros se encuentran en el siguiente espacio de Hugging Face: <a href="https://huggingface.co/spaces/nateraw/quickdraw/tree/main"></a>
Lo primero que debemos es, descargar los ficheros siguientes:
- class_names.txt
- pytorch_model.bin
- app.py</p>
<p>Analizamos el c√≥digo elaborado por el usuario:
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>  <span class="c1"># Importa el m√≥dulo para manejar rutas y archivos de forma sencilla.</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>              <span class="c1"># Importa la librer√≠a PyTorch, utilizada para deep learning y manipulaci√≥n de tensores.</span>
<span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">gradio</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">gr</span>       <span class="c1"># Importa Gradio, una librer√≠a para crear interfaces web de prueba.</span>
</span><span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>      <span class="c1"># Importa el subm√≥dulo para redes neuronales de PyTorch.</span>
<span class="hll">
</span><span class="c1"># Lee las etiquetas/clases del archivo de texto, una por l√≠nea. Cada l√≠nea es una categor√≠a que el modelo puede predecir.</span>
<span class="hll"><span class="n">LABELS</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;class_names.txt&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read_text</span><span class="p">()</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>
</span>
<span class="c1"># Definimos la arquitectura de la red neuronal convolucional (CNN) ya entrenada:</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>  <span class="c1"># Primera capa: 1 canal de entrada, 32 filtros, tama√±o de filtro 3x3</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>                            <span class="c1"># Funci√≥n de activaci√≥n no lineal ReLU (acelera y facilita el aprendizaje)</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>                      <span class="c1"># Max Pooling: reduce la resoluci√≥n espacial de las caracter√≠sticas (comprime la imagen a la vez que mantiene zonas m√°s ‚Äúactivas‚Äù)</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span> <span class="c1"># Segunda capa: 32‚Üí64 filtros</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span><span class="c1"># Tercera capa: 64‚Üí128 filtros</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>                         <span class="c1"># Aplana los datos resultantes para prepararlos para las capas densas (total elementos = 128 canales * 3 * 3)</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1152</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>                 <span class="c1"># Capa totalmente conectada: de 1152 (productos anteriores) a 256 neuronas</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">LABELS</span><span class="p">)),</span>          <span class="c1"># Capa de salida: 1 neurona por clase del archivo de etiquetas</span>
<span class="p">)</span>
<span class="c1"># Carga los pesos entrenados previamente desde el archivo binario (estado del modelo)</span>
<span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;pytorch_model.bin&#39;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1"># Coloca el modelo en modo &quot;solo inferencia&quot; (no entrenamiento): no calcula gradientes ni actualiza pesos</span>

<span class="c1"># Funci√≥n de predicci√≥n principal: toma una imagen (array) y devuelve las top-5 categor√≠as con su probabilidad</span>
<span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">im</span><span class="p">):</span>
    <span class="c1"># Convierte el array de la imagen en un tensor, escala los valores a rango [0,1] y a√±ade dimensiones de batch y canal</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>            <span class="c1"># Desactiva el c√°lculo de gradientes (m√°s r√°pido, no entrena)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>               <span class="c1"># Hacemos pasar la imagen por el modelo (forward pass)</span>

    <span class="n">probabilities</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Calcula las probabilidades (softmax)</span>

    <span class="n">values</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">probabilities</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>              <span class="c1"># Obtiene las 5 clases m√°s probables</span>

    <span class="c1"># Devuelve un diccionario {clase: probabilidad} para las 5 mejores</span>
    <span class="k">return</span> <span class="p">{</span><span class="n">LABELS</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="n">v</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">)}</span>

<span class="c1"># Crea la interfaz web con Gradio:</span>
<span class="c1">#   - predict: funci√≥n a ejecutar al recibir la entrada.</span>
<span class="c1">#   - inputs: &#39;sketchpad&#39;, una zona para que el usuario dibuje a mano alzada.</span>
<span class="c1">#   - outputs: &#39;label&#39;, salida tipo clasificaci√≥n de etiquetas.</span>
<span class="c1">#   - live=True: muestra predicciones en tiempo real mientras dibujas.</span>
<span class="n">interface</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">Interface</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="s1">&#39;sketchpad&#39;</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="n">live</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Lanza la aplicaci√≥n en local con debug activo. Abre una pesta√±a del navegador con la interfaz.</span>
<span class="n">interface</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">debug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
NOTA</p>
<h3 id="que-es-una-red-neuronal-convolucional-cnn">¬øQu√© es una red neuronal convolucional (CNN)?</h3>
<p>Una <strong>red neuronal convolucional</strong> (CNN, por sus siglas en ingl√©s, <em>Convolutional Neural Network</em>) es un tipo de red neuronal artificial especialmente dise√±ada para procesar datos que tienen una estructura en forma de cuadr√≠cula, como im√°genes, audio o v√≠deo.</p>
<h3 id="caracteristicas-principales">Caracter√≠sticas principales</h3>
<ul>
<li>
<p><strong>Inspiraci√≥n biol√≥gica:</strong><br />
  Las CNNs se inspiran en la corteza visual de los mam√≠feros. Primero detectan reglas simples (l√≠neas, bordes) y despu√©s patrones m√°s complejos (formas, objetos).</p>
</li>
<li>
<p><strong>Arquitectura en capas:</strong><br />
  Una CNN est√° compuesta por diferentes capas conectadas:</p>
<ul>
<li><strong>Capas convolucionales:</strong> Aplican filtros o ‚Äúkernels‚Äù para extraer patrones y caracter√≠sticas locales (bordes, texturas, esquinas).</li>
<li><strong>Capas de activaci√≥n (ReLU):</strong> Introducen no linealidad, permitiendo que la red aprenda funciones m√°s complejas.</li>
<li><strong>Capas de agrupamiento (pooling):</strong> Reducen la resoluci√≥n espacial y la cantidad de computaci√≥n, logrando robustez ante desplazamientos.</li>
<li><strong>Capas totalmente conectadas:</strong> Integran toda la informaci√≥n para tomar decisiones y realizar la predicci√≥n final.</li>
</ul>
</li>
<li>
<p><strong>Aprendizaje jer√°rquico:</strong><br />
  Las CNNs aprenden jerarqu√≠as de caracter√≠sticas:<br />
  Las primeras capas detectan elementos simples, las siguientes combinan estos elementos y las √∫ltimas reconocen patrones complejos y abstractos.</p>
</li>
<li>
<p><strong>Campos receptivos y par√°metros compartidos:</strong><br />
  Los filtros se aplican en toda la imagen usando los mismos par√°metros, lo que permite detectar el mismo patr√≥n en distintas posiciones. As√≠, el n√∫mero de par√°metros y el coste de memoria disminuyen en comparaci√≥n con una red completamente conectada.</p>
</li>
</ul>
<h3 id="aplicaciones-tipicas">Aplicaciones t√≠picas</h3>
<ul>
<li><strong>Reconocimiento y clasificaci√≥n de im√°genes:</strong> Detecci√≥n de objetos, diagn√≥stico m√©dico, moderaci√≥n de contenido, etc.</li>
<li><strong>Visi√≥n por computador:</strong> Conducci√≥n aut√≥noma, videovigilancia, an√°lisis de tr√°fico.</li>
<li><strong>Procesamiento de v√≠deo:</strong> Reconocimiento de acciones, seguimiento de objetos en secuencias de im√°genes, an√°lisis deportivo.</li>
</ul>
<h3 id="ejemplo-didactico-sencillo">Ejemplo did√°ctico sencillo</h3>
<p>Cuando pasas una imagen por una CNN:
- Las primeras capas detectan bordes y formas sencillas.
- Las siguientes detectan partes m√°s grandes (ruedas, patas, ojos).
- Al final, la red puede identificar el objeto completo (ej. ‚Äúbicicleta‚Äù, ‚Äúgato‚Äù, ‚Äúpersona‚Äù) en la imagen.</p>
<hr />
<p>Soluci√≥n final:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="hll">
</span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="hll"><span class="kn">import</span><span class="w"> </span><span class="nn">gradio</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">gr</span>
</span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="hll">
</span><span class="c1"># Leemos las etiquetas de clases (categor√≠as) desde un fichero de texto</span>
<span class="n">LABELS</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;class_names.txt&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read_text</span><span class="p">()</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>

<span class="c1"># Definimos nuestra red neuronal convolucional (la arquitectura fue entrenada previamente)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>  <span class="c1"># Capa convolucional: 1 canal de entrada (gris), 32 filtros, kernel 3x3</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>                            <span class="c1"># Funci√≥n de activaci√≥n ReLU</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>                      <span class="c1"># Pooling para reducir tama√±o espacial</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span> <span class="c1"># Segunda capa convolucional: 64 filtros</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span><span class="c1"># Tercera capa convolucional: 128 filtros</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>                         <span class="c1"># Aplana la salida para conectarla a las capas densas</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1152</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>                 <span class="c1"># Capa densa/intermedia</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">LABELS</span><span class="p">)),</span>          <span class="c1"># Capa de salida, un nodo por categor√≠a</span>
<span class="p">)</span>
<span class="c1"># Cargamos los pesos previamente entrenados del modelo</span>
<span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;pytorch_model.bin&#39;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Ponemos el modelo en modo inferencia (no entrenamiento)</span>

<span class="c1"># Funci√≥n principal de predicci√≥n, procesar√° el dibujo de Gradio y calcular√° su clase</span>
<span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>   
    <span class="c1"># Si no hay dibujo o la clave &#39;composite&#39; no existe o est√° vac√≠a, avisamos:</span>
    <span class="k">if</span> <span class="n">img</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="s2">&quot;composite&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">img</span> <span class="ow">or</span> <span class="n">img</span><span class="p">[</span><span class="s2">&quot;composite&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;Por favor, dibuja algo&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">}</span>
    <span class="c1"># Extraemos la imagen resultado del canvas, canal RGBA</span>
    <span class="n">arr</span> <span class="o">=</span> <span class="n">img</span><span class="p">[</span><span class="s2">&quot;composite&quot;</span><span class="p">]</span>        <span class="c1"># Array con forma (ej. [800, 800, 4]), tipo uint8</span>
    <span class="c1"># Convertimos de RGBA a escala de grises (Quick Draw es gris)</span>
    <span class="n">arr_gray</span> <span class="o">=</span> <span class="n">arr</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="c1"># Convertimos a uint8 por si PIL lo necesita</span>
    <span class="n">arr_gray_uint8</span> <span class="o">=</span> <span class="n">arr_gray</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;uint8&quot;</span><span class="p">)</span>
    <span class="c1"># Redimensionamos a 28x28 p√≠xeles (tama√±o de entrada del modelo)</span>
    <span class="n">arr_img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">arr_gray_uint8</span><span class="p">)</span>
    <span class="n">arr_resized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">arr_img</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">resample</span><span class="o">=</span><span class="n">Image</span><span class="o">.</span><span class="n">BILINEAR</span><span class="p">))</span>
    <span class="c1"># Escalamos a rango [0,1]</span>
    <span class="n">arr_normalized</span> <span class="o">=</span> <span class="n">arr_resized</span> <span class="o">/</span> <span class="mf">255.0</span>
    <span class="c1"># A√±adimos dimensiones de batch y canal: (1, 1, 28, 28)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">arr_normalized</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># Ejecutamos inferencia sin calcular gradientes (m√°s eficiente)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># Calculamos probabilidades con softmax</span>
    <span class="n">probabilities</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># Obtenemos las 5 clases m√°s probables (top-5)</span>
    <span class="n">values</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">probabilities</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="c1"># Devolvemos un diccionario: categor√≠a : probabilidad (~confianza)</span>
    <span class="k">return</span> <span class="p">{</span><span class="n">LABELS</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="n">v</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">)}</span>

<span class="c1"># Creamos la interfaz Gradio:</span>
<span class="c1"># - El input es un sketchpad (zona para dibujar)</span>
<span class="c1"># - El output son etiquetas: las categor√≠as predecidas</span>
<span class="c1"># - live=True: actualiza la predicci√≥n en tiempo real al dibujar</span>
<span class="n">demo</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">Interface</span><span class="p">(</span>
    <span class="n">predict</span><span class="p">,</span>     
    <span class="n">inputs</span><span class="o">=</span><span class="s1">&#39;sketchpad&#39;</span><span class="p">,</span>
    <span class="n">outputs</span><span class="o">=</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> 
    <span class="n">live</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Lanzamos la app Gradio (share=True permite compartir la URL con otros)</span>
<span class="n">demo</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">share</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h2 id="2-deteccion-de-objetos">2. Detecci√≥n de objetos</h2>
<p><img alt="Tasks - Object detection in Hugging Face" src="../img/object-detecction-hf.png" /></p>
<p>La detecci√≥n de objetos predice la distancia de cada p√≠xel respecto a la c√°mara usando solo una imagen. Es una t√©cnica fundamental en visi√≥n computacional que permite identificar y localizar instancias de objetos definidos dentro de im√°genes. Es ampliamente utilizada en aplicaciones como conducci√≥n aut√≥noma, seguimiento de objetos en deportes, b√∫squeda de im√°genes y conteo de objetos en diferentes escenarios. </p>
<p>Hugging Face alberga varios modelos que han sido entrenados previamente para detectar objetos en im√°genes. Podemos ver una lista de modelos en <a href="https://huggingface.co/models?pipeline_tag=object-detection&amp;sort=trending"></a> </p>
<p>En la figura siguiente podemos visualizar un listado de la categor√≠a <em>Object Detection</em>:</p>
<p><img alt="" src="../img/tasks_hf_object_detection.png" /></p>
<p>Ejemplo del <strong>facebook/detr-resnet-50</strong> para la detecci√≥n de objetos:</p>
<p><img alt="" src="../img/tasks_hf_object_detection_example.png" /></p>
<p>Podemos probar el modelo directamente utilizando la API de inferencia alojada en Hugging Face. Para ello, usaremos una imagen de una oficina con algunas mujeres <a href="https://en.wikipedia.org/wiki/Office#/media/File:Good_Smile_Company_offices_ladies.jpg;"></a>. </p>
<p><img alt="" src="../img/Good_Smile_Company_offices_ladies.jpg" /></p>
<p>Al arrastrar y soltar la imagen en la secci√≥n "Inference API" alojada en la p√°gina del modelo en Hugging Face, veremos la lista de objetos detectados, as√≠ como sus probabilidades correspondientes:</p>
<p>Objetos detectados en la imagen y sus probabilidades correspondientes:
<img alt="" src="../img/object_detection_good_Smile_Company_offices_ladies.png" /></p>
<p>Al pasar el rat√≥n por encima del nombre de un objeto detectado, la imagen resalta el cuadro delimitador del objeto seleccionado.</p>
<h3 id="algunos-modelos-disponibles-en-hugging-face">Algunos modelos disponibles en Hugging Face</h3>
<p>Hugging Face ofrece modelos preentrenados que permiten realizar detecci√≥n de objetos sin necesidad de entrenamiento adicional.</p>
<table>
<thead>
<tr>
<th>Modelo</th>
<th>Arquitectura</th>
<th>Dataset</th>
<th>Enlace</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>facebook/detr-resnet-50</code></td>
<td>DETR (DEtection TRansformer)</td>
<td>COCO</td>
<td>üîó <a href="https://huggingface.co/facebook/detr-resnet-50">Ver modelo</a></td>
</tr>
<tr>
<td><code>hustvl/yolos-small</code></td>
<td>YOLOS (Vision Transformer)</td>
<td>COCO</td>
<td>üîó Ver modelo</td>
</tr>
</tbody>
</table>
<h3 id="principales-aplicaciones">Principales Aplicaciones</h3>
<ul>
<li><strong>Conducci√≥n aut√≥noma:</strong> Los coches sin conductor usan la detecci√≥n de objetos para reconocer peatones, bicicletas, sem√°foros y se√±ales de tr√°fico, ayudando a la toma de decisiones en tiempo real.</li>
<li><strong>Seguimiento en deportes:</strong> En partidos de f√∫tbol o tenis se rastrea el bal√≥n o los jugadores para mejorar el arbitraje y el an√°lisis estad√≠stico.</li>
<li><strong>B√∫squeda de im√°genes:</strong> Los tel√©fonos inteligentes permiten buscar lugares u objetos directamente en internet mediante la detecci√≥n de entidades en fotos.</li>
<li><strong>Conteo de objetos:</strong> La detecci√≥n ayuda a contar existencias en almacenes, tiendas, o personas en eventos.</li>
</ul>
<h3 id="metricas-de-evaluacion">M√©tricas de Evaluaci√≥n</h3>
<ul>
<li><strong>Precisi√≥n media promedio (AP):</strong> √Årea bajo la curva de precisi√≥n versus recall para cada clase.</li>
<li><strong>mAP (mean Average Precision):</strong> Promedio de AP en todas las clases.</li>
<li><strong>APŒ±:</strong> Precisi√≥n promedio seg√∫n el umbral de IoU (por ejemplo, AP50 muestra AP cuando el IoU es &gt;0,5).</li>
</ul>
<h3 id="ejemplo-de-uso-con-gradio">Ejemplo de uso con Gradio</h3>
<p>Vamos a crear una aplicaci√≥n web con Gradio que use el modelo creado en una sesi√≥n anterior: <a href="https://huggingface.co/omarques/autotrain-dogs-and-cats-1527055142">‚Äãomarques/autotrain-dogs-and-cats-1527055142</a>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span> 

<span class="n">segmentation</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;image-segmentation&quot;</span><span class="p">,</span>  
               <span class="n">model</span><span class="o">=</span><span class="s2">&quot;nvidia/segformer-b0-finetuned-ade-512-512&quot;</span><span class="p">)</span> 

<span class="n">segmentation</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">id2label</span>
</code></pre></div></p>
<h2 id="3-segmentacion-de-imagenes-image-segmentation">3. Segmentaci√≥n de im√°genes (Image segmentation)</h2>
<p>Otra t√©cnica de visi√≥n por computadora com√∫nmente utilizada es la segmentaci√≥n de im√°genes. La segmentaci√≥n de im√°genes es una t√©cnica que consiste en separar una imagen en varios segmentos o regiones. Cada segmento corresponde a un objeto de inter√©s particular. Con la segmentaci√≥n de im√°genes, podemos analizar una imagen y extraer informaci√≥n valiosa de ella. </p>
<p>Algunos de sus usos son: </p>
<ul>
<li><strong>Im√°genes m√©dicas</strong>: se utilizan para identificar y segmentar tumores en resonancias magn√©ticas o tomograf√≠as computarizadas </li>
<li><strong>Detecci√≥n y reconocimiento de objetos</strong>: al igual que la detecci√≥n de objetos que hemos visto anteriormente, tambi√©n podemos utilizar la segmentaci√≥n de im√°genes para identificar y localizar objetos en una imagen </li>
<li><strong>Procesamiento de documentos</strong>: se utiliza para segmentar regiones de texto en documentos escaneados </li>
<li><strong>Biometr√≠a</strong>: se utiliza para identificar y localizar rostros en im√°genes o fotogramas de v√≠deo </li>
</ul>
<p>Hugging Face contiene varios modelos de segmentaci√≥n de im√°genes que podemos utilizar. Uno de ellos es el modelo "SegFormer model fine-tuned on ADE20k" (https://huggingface.co/nvidia/segformer-b0-finetuned-ade-512-512). 
La siguente imagen muestra el modelo SegFormer ajustado en el modelo ADE20k en el sitio web de Hugging Face:</p>
<p><img alt="" src="../img/tasks_image_segmentation_ade20k_hf.png" /></p>
<p>Para probar el modelo de segmentaci√≥n, usaremos una imagen del Taj Mahal. La arrastraremos y la soltaremos en la secci√≥n de "Hosted inference API" alojada en la p√°gina de Hugging Face:</p>
<p>Imagen del Taj Mahal (Fuente: https://mng.bz/5vzD)
<img alt="" src="../img/Taj_Mahal_Agra%2C_India_edit3.jpg" /></p>
<p>Resultado de la segmentaci√≥n de im√°genes utilizando una imagen del Taj Mahal:
<img alt="" src="../img/tasks_image_segmentation_taj_mahal_result.png" /></p>
<p>Como podomos ver en el resultado, el modelo puede detectar diferentes objetos (como edificios, cielos, √°rboles, etc.) en la imagen y resaltar los diversos segmentos en la imagen. De hecho, podemos pasar el rat√≥n sobre las diversas etiquetas segmentadas y la imagen resaltar√° dicha etiqueta seleccionada. </p>
<h3 id="31-uso-del-modelo-con-pipeline">3.1. Uso del modelo con pipeline</h3>
<p>Como es habitual, usaremos el modelo mediante programaci√≥n. Primero, cargamos el modelo y luego verificamos cu√°ntos objetos puede detectar el modelo. La forma m√°s f√°cil de usar el modelo es usar un pipeline  de la librer√≠a transformer: 
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span> 

<span class="n">segmentation</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;image-segmentation&quot;</span><span class="p">,</span>  
               <span class="n">model</span><span class="o">=</span><span class="s2">&quot;nvidia/segformer-b0-finetuned-ade-512-512&quot;</span><span class="p">)</span> 

<span class="n">segmentation</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">id2label</span>
</code></pre></div>
Estos son los primeros y √∫ltimos cinco objetos que puede detectar (el modelo puede detectar un total de 150 objetos): 
<div class="highlight"><pre><span></span><code><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;wall&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;buildi</span><span class="kc">n</span><span class="err">g&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="mi">2</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;sky&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="mi">3</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">fl</span><span class="err">oor&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="mi">4</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">tree</span><span class="err">&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="err">...</span><span class="w"> </span>
<span class="w"> </span><span class="mi">145</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;shower&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="mi">146</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;radia</span><span class="kc">t</span><span class="err">or&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="mi">147</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;glass&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="mi">148</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;clock&#39;</span><span class="p">,</span><span class="w"> </span>
<span class="w"> </span><span class="mi">149</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;</span><span class="kc">fla</span><span class="err">g&#39;</span><span class="p">}</span><span class="w"> </span>
</code></pre></div>
Para este ejemplo, usaremos una imagen donde vemos a un hombre y a un avi√≥n que vuela por encima, para as√≠ descubrir los distintos segmentos de dicha imagen: </p>
<p><img alt="" src="../img/photo-1487553333251-6c8e26d3dc2c.avif" /> </p>
<p>Fuente: <a href="https://unsplash.com/photos/EC_GhFRGTAY">https://unsplash.com/photos/EC_GhFRGTAY</a></p>
<p>Para detectar los distintos segmentos de la imagen, pasamos la direcci√≥n URL de una imagen al objeto <em>pipeline</em>: 
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>

<span class="hll"><span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://bit.ly/46iDeJQ&#39;</span>
</span>
<span class="hll"><span class="n">results</span> <span class="o">=</span> <span class="n">segmentation</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</span>
<span class="hll"><span class="n">results</span>
</span></code></pre></div></td></tr></table></div>
La salida de la variable <em>results</em> es una lista de diccionarios que contiene detalles de cada uno de los segmentos detectados en la imagen: 
<div class="highlight"><pre><span></span><code><span class="p">[{</span><span class="err">&#39;score&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">No</span><span class="kc">ne</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;label&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;wall&#39;</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;mask&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&lt;PIL.Image.Image</span><span class="w"> </span><span class="err">image</span><span class="w"> </span><span class="err">mode=L</span><span class="w"> </span><span class="err">size=</span><span class="mi">1587</span><span class="err">x</span><span class="mi">2381</span><span class="err">&gt;</span><span class="p">},</span>
<span class="w"> </span><span class="p">{</span><span class="err">&#39;score&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">No</span><span class="kc">ne</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;label&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;buildi</span><span class="kc">n</span><span class="err">g&#39;</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;mask&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&lt;PIL.Image.Image</span><span class="w"> </span><span class="err">image</span><span class="w"> </span><span class="err">mode=L</span><span class="w"> </span><span class="err">size=</span><span class="mi">1587</span><span class="err">x</span><span class="mi">2381</span><span class="err">&gt;</span><span class="p">},</span>
<span class="w"> </span><span class="p">{</span><span class="err">&#39;score&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">No</span><span class="kc">ne</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;label&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;sky&#39;</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;mask&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&lt;PIL.Image.Image</span><span class="w"> </span><span class="err">image</span><span class="w"> </span><span class="err">mode=L</span><span class="w"> </span><span class="err">size=</span><span class="mi">1587</span><span class="err">x</span><span class="mi">2381</span><span class="err">&gt;</span><span class="p">},</span>
<span class="w"> </span><span class="p">{</span><span class="err">&#39;score&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">No</span><span class="kc">ne</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;label&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;perso</span><span class="kc">n</span><span class="err">&#39;</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;mask&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&lt;PIL.Image.Image</span><span class="w"> </span><span class="err">image</span><span class="w"> </span><span class="err">mode=L</span><span class="w"> </span><span class="err">size=</span><span class="mi">1587</span><span class="err">x</span><span class="mi">2381</span><span class="err">&gt;</span><span class="p">},</span>
<span class="w"> </span><span class="p">{</span><span class="err">&#39;score&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">No</span><span class="kc">ne</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;label&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&#39;airpla</span><span class="kc">ne</span><span class="err">&#39;</span><span class="p">,</span>
<span class="w">  </span><span class="err">&#39;mask&#39;</span><span class="p">:</span><span class="w"> </span><span class="err">&lt;PIL.Image.Image</span><span class="w"> </span><span class="err">image</span><span class="w"> </span><span class="err">mode=L</span><span class="w"> </span><span class="err">size=</span><span class="mi">1587</span><span class="err">x</span><span class="mi">2381</span><span class="err">&gt;</span><span class="p">}]</span>
</code></pre></div>
En particular, el elemento <em>mask</em> contiene la m√°scara del segmento detectado. Para ver cada una de las m√°scaras detectadas, recorremos la variable <em>results</em>: </p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
<span class="hll">    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>
</span><span class="hll">    <span class="n">display</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;mask&#39;</span><span class="p">])</span>
</span></code></pre></div></td></tr></table></div>
<p>La figura siguiente muestra las m√°scaras detectadas para <em>person</em> (persona) y <em>airplane</em> (avi√≥n):
<img alt="" src="../img/parte_blanca_hombre_avion.jpg" /></p>
<p>M√°scaras para los segmentos <em>person</em> y <em>airplane</em></p>
<p>La parte blanca de la m√°scara representa la parte de la imagen que contiene el segmento de inter√©s. Podemos aplicar la m√°scara sobre la imagen original mediante el siguiente fragmento de c√≥digo: </p>
<p><div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">raw</span><span class="p">)</span> 

<span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span> 
    <span class="n">base_image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> 
    <span class="n">mask_image</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;mask&#39;</span><span class="p">]</span> 

    <span class="c1"># Aplica la m√°scara sobre la imagen original</span>
<span class="hll">    <span class="n">base_image</span><span class="o">.</span><span class="n">paste</span><span class="p">(</span><span class="n">mask_image</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask_image</span><span class="p">)</span> 
</span>    <span class="c1">#Imprime la etiqueta del segmento</span>
<span class="hll">    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span> 
</span>    <span class="n">display</span><span class="p">(</span><span class="n">base_image</span><span class="p">)</span> 
</code></pre></div></td></tr></table></div>
La figura siguiente muestra las m√°scaras de <em>person</em> (persona) y <em>airplane</em> (avi√≥n) aplicadas sobre la imagen original:
<img alt="" src="../img/mascaras_en_imagen_original.jpg" /></p>
<p>Cuando aplicamos la m√°scara sobre la imagen, observaremos que el segmento de inter√©s est√° en blanco. Ser√≠a m√°s natural invertir esto, es decir, el segmento de inter√©s deber√≠a mostrarse mientras que el resto deber√≠a estar en blanco. Para hacer esto, puede invertir la m√°scara usando la funci√≥n <code>invert()</code> de la clase <code>ImageOps</code> en el paquete <code>PIL</code>. Los siguientes cambios invierten la m√°scara y, a continuaci√≥n, la aplican sobre la imagen original: </p>
<p><div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">ImageOps</span> 

<span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span> 
    <span class="n">base_image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> 
    <span class="n">mask_image</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;mask&#39;</span><span class="p">]</span> 

    <span class="n">mask_image</span> <span class="o">=</span> <span class="n">ImageOps</span><span class="o">.</span><span class="n">invert</span><span class="p">(</span><span class="n">mask_image</span><span class="p">)</span>  <span class="c1">#Invierte la m√°scara </span>
<span class="hll">    <span class="n">base_image</span><span class="o">.</span><span class="n">paste</span><span class="p">(</span><span class="n">mask_image</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask_image</span><span class="p">)</span>  <span class="c1">#Aplica la m√°scara sobre la imagen original </span>
</span>    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>  <span class="c1">#Imprime la etiqueta del segmento</span>
<span class="hll">    <span class="n">display</span><span class="p">(</span><span class="n">base_image</span><span class="p">)</span> 
</span></code></pre></div></td></tr></table></div>
La figura siguiente muestra las m√°scaras invertidas para <em>person</em> (persona) y <em>airplane</em> (avi√≥n)aplicadas en la imagen original. </p>
<p><img alt="" src="../img/imagenes_mascaras_invertidas.jpg" /></p>
<h3 id="32-enlazando-con-gradio">3.2. Enlazando con Gradio</h3>
<p>En lugar de especificar manualmente la direcci√≥n URL de la imagen que queremos usar en el modelo, ser√≠a m√°s conveniente crear una interfaz de usuario para que probemos el modelo de segmentaci√≥n. Tal y como ya hemos utilizado anteiriormente, vamos a hacer uso del paquete Gradio para crear una interfaz de usuario y luego vincularla a la funci√≥n que realiza la segmentaci√≥n. </p>
<h2 id="actividades">Actividades</h2>
<ol>
<li><strong>Usar un Space de Hugging Face</strong><br />
Utiliza el pipeline:</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>

<span class="n">depth</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;depth-estimation&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;Intel/zoedepth-nyu-kitti&quot;</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">depth</span><span class="p">(</span><span class="s2">&quot;ruta_o_url_imagen&quot;</span><span class="p">)</span>
</code></pre></div>
<ol>
<li><strong>Clasificaci√≥n de im√°genes</strong>
Crear un aplicaci√≥n con Gradio 
En lugar de especificar manualmente la direcci√≥n URL de la imagen que queremos usar en el modelo, ser√≠a m√°s conveniente crear una interfaz de usuario para que el usuario pruebe el modelo de segmentaci√≥n. Aqu√≠, vamos a hacer uso del paquete Gradio para crear una interfaz de usuario y luego vincularla a la funci√≥n que realiza la segmentaci√≥n. </li>
</ol>
<p>Usa el pipeline:
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;image-classification&quot;</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;ruta_o_url_imagen&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</code></pre></div></p>
<ol>
<li><strong>Avanzado (Optativo): Integrar clasificaci√≥n y segmentaci√≥n</strong> </li>
</ol>
<p>Ejecuta ambos pipelines y visualiza el resultado conjunto.</p>







  
  






                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Volver al principio
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Pie" >
        
          
          <a href="../Ejemplo_gradio/" class="md-footer__link md-footer__link--prev" aria-label="Anterior: Gradio">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Anterior
              </span>
              <div class="md-ellipsis">
                Gradio
              </div>
            </div>
          </a>
        
        
          
          <a href="../Referencias/" class="md-footer__link md-footer__link--next" aria-label="Siguiente: Referencias">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Siguiente
              </span>
              <div class="md-ellipsis">
                Referencias
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "toc.integrate", "navigation.expand", "navigation.top", "navigation.indexes", "content.tabs.link", "content.code.annotate", "content.code.copy", "navigation.footer"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copiado al portapapeles", "clipboard.copy": "Copiar al portapapeles", "search.result.more.one": "1 m\u00e1s en esta p\u00e1gina", "search.result.more.other": "# m\u00e1s en esta p\u00e1gina", "search.result.none": "No se encontraron documentos", "search.result.one": "1 documento encontrado", "search.result.other": "# documentos encontrados", "search.result.placeholder": "Teclee para comenzar b\u00fasqueda", "search.result.term.missing": "Falta", "select.version": "Seleccionar versi\u00f3n"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>